{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADvCy-DXOQvx",
        "outputId": "c95e5b00-9c37-44c7-a77f-b8c102f0d9f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "!pip install utils\n",
        "from utils import *\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import numpy as np\n",
        "import time\n",
        "% matplotlib inline\n",
        "\n",
        "\n",
        "batch_size=16\n",
        "dataset = dset.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "xWlsLAXwOk0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = dataset[0]\n",
        "plt.imshow(to_pil_image(img))\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "JHcFJHU5OYTZ",
        "outputId": "2659ff5b-73ee-46a2-b353-54902b9a268f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOZ0lEQVR4nO3dbYxc5XnG8euKbezamMQbB9chLjjgFAg0Jl0ZEBZQobgOqgSoCsSKIkJpnSY4Ca0rQWlV3IpWbpUQUUqRTHExFS+BBIQ/0CTUQpCowWWhBgwEDMY0NmaNWYENIX5Z3/2w42iBnWeXmTMv3vv/k1Yzc+45c24NXD5nznNmHkeEAIx/H+p0AwDag7ADSRB2IAnCDiRB2IEkJrZzY4d5ckzRtHZuEkjlV3pbe2OPR6o1FXbbiyVdJ2mCpH+LiJWl50/RNJ3qc5rZJICC9bGubq3hw3jbEyTdIOnzkk6UtMT2iY2+HoDWauYz+wJJL0TE5ojYK+lOSedV0xaAqjUT9qMk/WLY4621Ze9ie6ntPtt9+7Snic0BaEbLz8ZHxKqI6I2I3kma3OrNAaijmbBvkzRn2ONP1JYB6ELNhP1RSfNsz7V9mKQvSlpbTVsAqtbw0FtE7Le9TNKPNDT0tjoinq6sMwCVamqcPSLul3R/Rb0AaCEulwWSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJpmZxRffzxPJ/4gkfm9nS7T/3F8fUrQ1OPVBc9+hjdxTrU7/uYv3Vaw+rW3u893vFdXcOvl2sn3r38mL9uD9/pFjvhKbCbnuLpN2SBiXtj4jeKpoCUL0q9uy/FxE7K3gdAC3EZ3YgiWbDHpJ+bPsx20tHeoLtpbb7bPft054mNwegUc0exi+MiG22j5T0gO2fR8TDw58QEaskrZKkI9wTTW4PQIOa2rNHxLba7Q5J90paUEVTAKrXcNhtT7M9/eB9SYskbayqMQDVauYwfpake20ffJ3bI+KHlXQ1zkw4YV6xHpMnFeuvnPWRYv2d0+qPCfd8uDxe/JPPlMebO+k/fzm9WP/Hf1lcrK8/+fa6tZf2vVNcd2X/54r1j//k0PtE2nDYI2KzpM9U2AuAFmLoDUiCsANJEHYgCcIOJEHYgST4imsFBs/+bLF+7S03FOufmlT/q5jj2b4YLNb/5vqvFOsT3y4Pf51+97K6tenb9hfXnbyzPDQ3tW99sd6N2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs1dg8nOvFOuP/WpOsf6pSf1VtlOp5dtPK9Y3v1X+Kepbjv1+3dqbB8rj5LP++b+L9VY69L7AOjr27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhCPaN6J4hHviVJ/Ttu11i4FLTi/Wdy0u/9zzhCcPL9af+Pr1H7ing67Z+TvF+qNnlcfRB994s1iP0+v/APGWbxZX1dwlT5SfgPdZH+u0KwZGnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMPOjxfrg6wPF+ku31x8rf/rM1cV1F/zDN4r1I2/o3HfK8cE1Nc5ue7XtHbY3DlvWY/sB25tqtzOqbBhA9cZyGH+LpPfOen+lpHURMU/SutpjAF1s1LBHxMOS3nsceZ6kNbX7aySdX3FfACrW6G/QzYqI7bX7r0qaVe+JtpdKWipJUzS1wc0BaFbTZ+Nj6Axf3bN8EbEqInojoneSJje7OQANajTs/bZnS1Ltdkd1LQFohUbDvlbSxbX7F0u6r5p2ALTKqJ/Zbd8h6WxJM21vlXS1pJWS7rJ9qaSXJV3YyibHu8Gdrze1/r5djc/v/ukvPVOsv3bjhPILHCjPsY7uMWrYI2JJnRJXxwCHEC6XBZIg7EAShB1IgrADSRB2IAmmbB4HTrji+bq1S04uD5r8+9HrivWzvnBZsT79e48U6+ge7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ceB0rTJr3/thOK6/7f2nWL9ymtuLdb/8sILivX43w/Xrc35+58V11Ubf+Y8A/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEUzYnN/BHpxfrt1397WJ97sQpDW/707cuK9bn3bS9WN+/eUvD2x6vmpqyGcD4QNiBJAg7kARhB5Ig7EAShB1IgrADSTDOjqI4Y36xfsTKrcX6HZ/8UcPbPv7BPy7Wf/tv63+PX5IGN21ueNuHqqbG2W2vtr3D9sZhy1bY3mZ7Q+3v3CobBlC9sRzG3yJp8QjLvxsR82t/91fbFoCqjRr2iHhY0kAbegHQQs2coFtm+8naYf6Mek+yvdR2n+2+fdrTxOYANKPRsN8o6VhJ8yVtl/Sdek+MiFUR0RsRvZM0ucHNAWhWQ2GPiP6IGIyIA5JukrSg2rYAVK2hsNuePezhBZI21nsugO4w6ji77TsknS1ppqR+SVfXHs+XFJK2SPpqRJS/fCzG2cejCbOOLNZfuei4urX1V1xXXPdDo+yLvvTSomL9zYWvF+vjUWmcfdRJIiJiyQiLb266KwBtxeWyQBKEHUiCsANJEHYgCcIOJMFXXNExd20tT9k81YcV67+MvcX6H3zj8vqvfe/64rqHKn5KGgBhB7Ig7EAShB1IgrADSRB2IAnCDiQx6rfekNuBheWfkn7xC+Upm0+av6VubbRx9NFcP3BKsT71vr6mXn+8Yc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj7OufekYv35b5bHum86Y02xfuaU8nfKm7En9hXrjwzMLb/AgVF/3TwV9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7IeAiXOPLtZfvOTjdWsrLrqzuO4fHr6zoZ6qcFV/b7H+0HWnFesz1pR/dx7vNuqe3fYc2w/afsb207a/VVveY/sB25tqtzNa3y6ARo3lMH6/pOURcaKk0yRdZvtESVdKWhcR8yStqz0G0KVGDXtEbI+Ix2v3d0t6VtJRks6TdPBayjWSzm9VkwCa94E+s9s+RtIpktZLmhURBy8+flXSrDrrLJW0VJKmaGqjfQJo0pjPxts+XNIPJF0eEbuG12JodsgRZ4iMiFUR0RsRvZM0ualmATRuTGG3PUlDQb8tIu6pLe63PbtWny1pR2taBFCFUQ/jbVvSzZKejYhrh5XWSrpY0sra7X0t6XAcmHjMbxXrb/7u7GL9or/7YbH+px+5p1hvpeXby8NjP/vX+sNrPbf8T3HdGQcYWqvSWD6znyHpy5Kesr2htuwqDYX8LtuXSnpZ0oWtaRFAFUYNe0T8VNKIk7tLOqfadgC0CpfLAkkQdiAJwg4kQdiBJAg7kARfcR2jibN/s25tYPW04rpfm/tQsb5ken9DPVVh2baFxfrjN5anbJ75/Y3Fes9uxsq7BXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUgizTj73t8v/2zx3j8bKNavOu7+urVFv/F2Qz1VpX/wnbq1M9cuL657/F//vFjveaM8Tn6gWEU3Yc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkGWffcn7537XnT767Zdu+4Y1ji/XrHlpUrHuw3o/7Djn+mpfq1ub1ry+uO1isYjxhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTgiyk+w50i6VdIsSSFpVURcZ3uFpD+R9FrtqVdFRP0vfUs6wj1xqpn4FWiV9bFOu2JgxAszxnJRzX5JyyPicdvTJT1m+4Fa7bsR8e2qGgXQOmOZn327pO21+7ttPyvpqFY3BqBaH+gzu+1jJJ0i6eA1mMtsP2l7te0ZddZZarvPdt8+7WmqWQCNG3PYbR8u6QeSLo+IXZJulHSspPka2vN/Z6T1ImJVRPRGRO8kTa6gZQCNGFPYbU/SUNBvi4h7JCki+iNiMCIOSLpJ0oLWtQmgWaOG3bYl3Szp2Yi4dtjy2cOedoGk8nSeADpqLGfjz5D0ZUlP2d5QW3aVpCW252toOG6LpK+2pEMAlRjL2fifShpp3K44pg6gu3AFHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlRf0q60o3Zr0l6ediimZJ2tq2BD6Zbe+vWviR6a1SVvR0dER8bqdDWsL9v43ZfRPR2rIGCbu2tW/uS6K1R7eqNw3ggCcIOJNHpsK/q8PZLurW3bu1LordGtaW3jn5mB9A+nd6zA2gTwg4k0ZGw215s+znbL9i+shM91GN7i+2nbG+w3dfhXlbb3mF747BlPbYfsL2pdjviHHsd6m2F7W21926D7XM71Nsc2w/afsb207a/VVve0feu0Fdb3re2f2a3PUHS85I+J2mrpEclLYmIZ9raSB22t0jqjYiOX4Bh+0xJb0m6NSJOqi37J0kDEbGy9g/ljIi4okt6WyHprU5P412brWj28GnGJZ0v6Svq4HtX6OtCteF968SefYGkFyJic0TslXSnpPM60EfXi4iHJQ28Z/F5ktbU7q/R0P8sbVent64QEdsj4vHa/d2SDk4z3tH3rtBXW3Qi7EdJ+sWwx1vVXfO9h6Qf237M9tJONzOCWRGxvXb/VUmzOtnMCEadxrud3jPNeNe8d41Mf94sTtC938KI+Kykz0u6rHa42pVi6DNYN42djmka73YZYZrxX+vke9fo9OfN6kTYt0maM+zxJ2rLukJEbKvd7pB0r7pvKur+gzPo1m53dLifX+umabxHmmZcXfDedXL6806E/VFJ82zPtX2YpC9KWtuBPt7H9rTaiRPZniZpkbpvKuq1ki6u3b9Y0n0d7OVdumUa73rTjKvD713Hpz+PiLb/STpXQ2fkX5T0V53ooU5fn5T0RO3v6U73JukODR3W7dPQuY1LJX1U0jpJmyT9l6SeLurtPyQ9JelJDQVrdod6W6ihQ/QnJW2o/Z3b6feu0Fdb3jculwWS4AQdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "s3IBMnSuOn2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.ConvTranspose2d(74, 1024, 1, 1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(1024)\n",
        "    self.conv2 = nn.ConvTranspose2d(1024, 128, 7, 1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(64)\n",
        "    self.conv4 = nn.ConvTranspose2d(64, 1, 4, 2, padding=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "    img = torch.sigmoid(self.conv4(x))\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "AXsd0s2COmsH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n",
        "    self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128, 1024, 7, 1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(1024)\n",
        "\n",
        "  def forward(self, img):\n",
        "    img = F.leaky_relu(self.conv1(img), 0.1, inplace=True)\n",
        "    img = F.leaky_relu(self.bn2(self.conv2(img)), 0.1, inplace=True)\n",
        "    img = F.leaky_relu(self.bn3(self.conv3(img)), 0.1, inplace=True)\n",
        "\n",
        "    return img\n",
        "\n",
        "# # test\n",
        "# dis = Discriminator().to(device)\n",
        "# img = torch.randn(16,1,28,28).to(device)\n",
        "# print(img.shape)\n",
        "# output = dis(img)\n",
        "# print(output.shape)"
      ],
      "metadata": {
        "id": "UuLMaUwaQGjI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DHead(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(1024, 1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = torch.sigmoid(self.conv(x))\n",
        "\n",
        "    return output\n",
        "\n",
        "class QHead(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1024, 128, 1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.conv_disc = nn.Conv2d(128, 10, 1)\n",
        "    self.conv_mu = nn.Conv2d(128, 2, 1)\n",
        "    self.conv_var = nn.Conv2d(128, 2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n",
        "\n",
        "      disc_logits = self.conv_disc(x).squeeze()\n",
        "\n",
        "      mu = self.conv_mu(x).squeeze()\n",
        "      var = torch.exp(self.conv_var(x).squeeze())\n",
        "\n",
        "      return disc_logits, mu, var"
      ],
      "metadata": {
        "id": "RcgrRjMqQ6Xh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight init & Parameter"
      ],
      "metadata": {
        "id": "kU54GdGdRoj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_init(model):\n",
        "  classname = model.__class__.__name__\n",
        "  if classname.find(\"conv\") != -1:\n",
        "    torch.nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "  elif classname.find(\"BatchNorm\") != -1:\n",
        "    torch.nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "    torch.nn.init.constant_(model.bias.data, 0.0)\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 20\n",
        "learning_rate = 2e-4\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "save_epoch = 25\n",
        "dataset = \"MNIST\"\n",
        "num_z = 62\n",
        "num_dis_c = 1\n",
        "dis_c_dim = 10\n",
        "num_con_c = 2"
      ],
      "metadata": {
        "id": "UHKkDEW8Rn0T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "EGsgD_uERvZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalNLLLoss:\n",
        "  def __call__(self, x, mu, var):\n",
        "    logli = -0.5 * (var.mul(2*np.pi) + 1e-6).log() - (x - mu).pow(2).div(var.mul(2.0) + 1e-6)\n",
        "    nll = -(logli.sum(1).mean())\n",
        "\n",
        "    return nll\n",
        "\n",
        "def noise_sample(n_dis_c, dis_c_dim, n_con_c, n_z, batch_size, device):\n",
        "  z = torch.randn(batch_size, n_z, 1, 1, device=device)\n",
        "\n",
        "  idx = np.zeros((n_dis_c, batch_size))\n",
        "  dis_c = torch.zeros(batch_size, n_dis_c, dis_c_dim, device=device)\n",
        "  for i in range(n_dis_c):\n",
        "    idx[i] = np.random.randint(dis_c_dim, size=batch_size)\n",
        "    dis_c[torch.arange(0, batch_size), i, idx[i]] = 1.0\n",
        "  dis_c = dis_c.view(batch_size, -1, 1, 1)\n",
        "\n",
        "  con_c = torch.rand(batch_size, n_con_c, 1, 1, device=device) * 2 -1\n",
        "\n",
        "  noise = z\n",
        "  noise = torch.cat((z, dis_c), dim=1)\n",
        "  noise = torch.cat((noise, con_c), dim=1)\n",
        "\n",
        "  return noise, idx"
      ],
      "metadata": {
        "id": "tlBPnsVBRtPo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the network.\n",
        "netG = Generator().to(device)\n",
        "netG.apply(weight_init)\n",
        "print(netG)\n",
        "\n",
        "discriminator = Discriminator().to(device)\n",
        "discriminator.apply(weight_init)\n",
        "print(discriminator)\n",
        "\n",
        "netD = DHead().to(device)\n",
        "netD.apply(weight_init)\n",
        "print(netD)\n",
        "\n",
        "netQ = QHead().to(device)\n",
        "netQ.apply(weight_init)\n",
        "print(netQ)\n",
        "\n",
        "# Loss for discrimination between real and fake images.\n",
        "criterionD = nn.BCELoss()\n",
        "# Loss for discrete latent code.\n",
        "criterionQ_dis = nn.CrossEntropyLoss()\n",
        "# Loss for continuous latent code.\n",
        "criterionQ_con = NormalNLLLoss()\n",
        "\n",
        "# Adam optimiser is used.\n",
        "optimD = optim.Adam([{'params': discriminator.parameters()}, {'params': netD.parameters()}], lr=learning_rate, betas=(beta1, beta2))\n",
        "optimG = optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=learning_rate, betas=(beta1, beta2))\n",
        "\n",
        "# Fixed Noise\n",
        "z = torch.randn(100, num_z, 1, 1, device=device)\n",
        "fixed_noise = z\n",
        "if(num_dis_c != 0):\n",
        "    idx = np.arange(dis_c_dim).repeat(10)\n",
        "    dis_c = torch.zeros(100, num_dis_c, dis_c_dim, device=device)\n",
        "    for i in range(num_dis_c):\n",
        "        dis_c[torch.arange(0, 100), i, idx] = 1.0\n",
        "\n",
        "    dis_c = dis_c.view(100, -1, 1, 1)\n",
        "\n",
        "    fixed_noise = torch.cat((fixed_noise, dis_c), dim=1)\n",
        "\n",
        "if(num_con_c != 0):\n",
        "    con_c = torch.rand(100, num_con_c, 1, 1, device=device) * 2 - 1\n",
        "    fixed_noise = torch.cat((fixed_noise, con_c), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIDmwoeXVPBV",
        "outputId": "924632db-4f0b-42f1-887c-e7f86a1c8f54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (conv1): ConvTranspose2d(74, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): ConvTranspose2d(1024, 128, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "Discriminator(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 1024, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "DHead(\n",
            "  (conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "QHead(\n",
            "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_disc): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_mu): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_var): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# List variables to store results pf training.\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "print(\"-\"*25)\n",
        "print(\"Starting Training Loop...\\n\")\n",
        "print(\"-\"*25)\n",
        "\n",
        "start_time = time.time()\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for i, (data, _) in enumerate(data_loader, 0):\n",
        "        # Get batch size\n",
        "        b_size = data.size(0)\n",
        "        # Transfer data tensor to GPU/CPU (device)\n",
        "        real_data = data.to(device)\n",
        "\n",
        "        # Updating discriminator and DHead\n",
        "        optimD.zero_grad()\n",
        "        # Real data\n",
        "        label = torch.full((b_size, ), real_label, device=device)\n",
        "        output1 = discriminator(real_data)\n",
        "        probs_real = netD(output1).view(-1)\n",
        "        loss_real = criterionD(probs_real.to(torch.float32), label.to(torch.float32))\n",
        "        # Calculate gradients.\n",
        "        loss_real.backward()\n",
        "\n",
        "        # Fake data\n",
        "        label.fill_(fake_label)\n",
        "        noise, idx = noise_sample(num_dis_c, dis_c_dim, num_con_c, num_z, b_size, device)\n",
        "        fake_data = netG(noise)\n",
        "        output2 = discriminator(fake_data.detach())\n",
        "        probs_fake = netD(output2).view(-1)\n",
        "        loss_fake = criterionD(probs_fake.to(torch.float32), label.to(torch.float32))\n",
        "        # Calculate gradients.\n",
        "        loss_fake.backward()\n",
        "\n",
        "        # Net Loss for the discriminator\n",
        "        D_loss = loss_real + loss_fake\n",
        "        # Update parameters\n",
        "        optimD.step()\n",
        "\n",
        "        # Updating Generator and QHead\n",
        "        optimG.zero_grad()\n",
        "\n",
        "        # Fake data treated as real.\n",
        "        output = discriminator(fake_data)\n",
        "        label.fill_(real_label)\n",
        "        probs_fake = netD(output).view(-1)\n",
        "        gen_loss = criterionD(probs_fake.to(torch.float32), label.to(torch.float32))\n",
        "\n",
        "        q_logits, q_mu, q_var = netQ(output)\n",
        "        target = torch.LongTensor(idx).to(device)\n",
        "        # Calculating loss for discrete latent code.\n",
        "        dis_loss = 0\n",
        "        for j in range(num_dis_c):\n",
        "            dis_loss += criterionQ_dis(q_logits[:, j*10 : j*10 + 10], target[j])\n",
        "\n",
        "        # Calculating loss for continuous latent code.\n",
        "        con_loss = 0\n",
        "        if (num_con_c != 0):\n",
        "            con_loss = criterionQ_con(noise[:, num_z+ num_dis_c*dis_c_dim : ].view(-1, num_con_c), q_mu, q_var)*0.1\n",
        "\n",
        "        # Net loss for generator.\n",
        "        G_loss = gen_loss + dis_loss + con_loss\n",
        "        # Calculate gradients.\n",
        "        G_loss.backward()\n",
        "        # Update parameters.\n",
        "        optimG.step()\n",
        "\n",
        "        # Check progress of training.\n",
        "        if i != 0 and i%100 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
        "                  % (epoch+1, num_epochs, i, len(data_loader), \n",
        "                    D_loss.item(), G_loss.item()))\n",
        "\n",
        "        # Save the losses for plotting.\n",
        "        G_losses.append(G_loss.item())\n",
        "        D_losses.append(D_loss.item())\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(\"Time taken for Epoch %d: %.2fs\" %(epoch + 1, epoch_time))\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(\"-\"*50)\n",
        "print('Training finished!\\nTotal Time for Training: %.2fm' %(training_time / 60))\n",
        "print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5c6PsuDzo1s",
        "outputId": "5a40412c-5d82-4651-aabd-01775b71763e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "Starting Training Loop...\n",
            "\n",
            "-------------------------\n",
            "[1/20][100/3750]\tLoss_D: 1.3150\tLoss_G: 2.4151\n",
            "[1/20][200/3750]\tLoss_D: 1.1245\tLoss_G: 1.5657\n",
            "[1/20][300/3750]\tLoss_D: 1.0927\tLoss_G: 1.4570\n",
            "[1/20][400/3750]\tLoss_D: 0.9392\tLoss_G: 1.5683\n",
            "[1/20][500/3750]\tLoss_D: 1.0071\tLoss_G: 1.6882\n",
            "[1/20][600/3750]\tLoss_D: 1.1092\tLoss_G: 1.3561\n",
            "[1/20][700/3750]\tLoss_D: 0.8748\tLoss_G: 1.7551\n",
            "[1/20][800/3750]\tLoss_D: 0.8137\tLoss_G: 1.7288\n",
            "[1/20][900/3750]\tLoss_D: 0.7374\tLoss_G: 1.5974\n",
            "[1/20][1000/3750]\tLoss_D: 0.9371\tLoss_G: 1.6583\n",
            "[1/20][1100/3750]\tLoss_D: 1.1258\tLoss_G: 1.6345\n",
            "[1/20][1200/3750]\tLoss_D: 1.1121\tLoss_G: 1.4103\n",
            "[1/20][1300/3750]\tLoss_D: 1.0149\tLoss_G: 1.5897\n",
            "[1/20][1400/3750]\tLoss_D: 1.0989\tLoss_G: 1.2934\n",
            "[1/20][1500/3750]\tLoss_D: 0.9323\tLoss_G: 1.4440\n",
            "[1/20][1600/3750]\tLoss_D: 0.9135\tLoss_G: 1.7624\n",
            "[1/20][1700/3750]\tLoss_D: 0.9744\tLoss_G: 1.6775\n",
            "[1/20][1800/3750]\tLoss_D: 0.9200\tLoss_G: 1.4362\n",
            "[1/20][1900/3750]\tLoss_D: 0.9791\tLoss_G: 1.3833\n",
            "[1/20][2000/3750]\tLoss_D: 1.0729\tLoss_G: 1.4109\n",
            "[1/20][2100/3750]\tLoss_D: 0.7569\tLoss_G: 1.4592\n",
            "[1/20][2200/3750]\tLoss_D: 0.9996\tLoss_G: 1.5775\n",
            "[1/20][2300/3750]\tLoss_D: 1.0101\tLoss_G: 1.3943\n",
            "[1/20][2400/3750]\tLoss_D: 1.0654\tLoss_G: 1.4019\n",
            "[1/20][2500/3750]\tLoss_D: 1.1134\tLoss_G: 1.6187\n",
            "[1/20][2600/3750]\tLoss_D: 1.1769\tLoss_G: 1.3621\n",
            "[1/20][2700/3750]\tLoss_D: 1.1073\tLoss_G: 1.6528\n",
            "[1/20][2800/3750]\tLoss_D: 1.2909\tLoss_G: 1.2688\n",
            "[1/20][2900/3750]\tLoss_D: 0.8585\tLoss_G: 1.4944\n",
            "[1/20][3000/3750]\tLoss_D: 1.0922\tLoss_G: 1.4799\n",
            "[1/20][3100/3750]\tLoss_D: 1.2261\tLoss_G: 1.3744\n",
            "[1/20][3200/3750]\tLoss_D: 1.1407\tLoss_G: 1.3373\n",
            "[1/20][3300/3750]\tLoss_D: 0.9833\tLoss_G: 1.4077\n",
            "[1/20][3400/3750]\tLoss_D: 1.0239\tLoss_G: 1.4224\n",
            "[1/20][3500/3750]\tLoss_D: 0.9248\tLoss_G: 1.4102\n",
            "[1/20][3600/3750]\tLoss_D: 1.1992\tLoss_G: 1.2061\n",
            "[1/20][3700/3750]\tLoss_D: 0.8668\tLoss_G: 1.5709\n",
            "Time taken for Epoch 1: 316.40s\n",
            "[2/20][100/3750]\tLoss_D: 1.0461\tLoss_G: 1.4245\n",
            "[2/20][200/3750]\tLoss_D: 1.0459\tLoss_G: 1.3523\n",
            "[2/20][300/3750]\tLoss_D: 1.0872\tLoss_G: 1.3567\n",
            "[2/20][400/3750]\tLoss_D: 1.1091\tLoss_G: 1.5852\n",
            "[2/20][500/3750]\tLoss_D: 1.1467\tLoss_G: 1.2201\n",
            "[2/20][600/3750]\tLoss_D: 1.1629\tLoss_G: 1.4193\n",
            "[2/20][700/3750]\tLoss_D: 1.1695\tLoss_G: 1.2201\n",
            "[2/20][800/3750]\tLoss_D: 1.1164\tLoss_G: 1.2059\n",
            "[2/20][900/3750]\tLoss_D: 1.0696\tLoss_G: 1.1608\n",
            "[2/20][1000/3750]\tLoss_D: 1.2891\tLoss_G: 1.0868\n",
            "[2/20][1100/3750]\tLoss_D: 1.1289\tLoss_G: 1.2619\n",
            "[2/20][1200/3750]\tLoss_D: 1.0121\tLoss_G: 1.2956\n",
            "[2/20][1300/3750]\tLoss_D: 1.0554\tLoss_G: 1.3153\n",
            "[2/20][1400/3750]\tLoss_D: 1.1255\tLoss_G: 1.2162\n",
            "[2/20][1500/3750]\tLoss_D: 0.9287\tLoss_G: 1.2525\n",
            "[2/20][1600/3750]\tLoss_D: 1.0582\tLoss_G: 1.3072\n",
            "[2/20][1700/3750]\tLoss_D: 1.1931\tLoss_G: 1.0551\n",
            "[2/20][1800/3750]\tLoss_D: 1.0314\tLoss_G: 1.2724\n",
            "[2/20][1900/3750]\tLoss_D: 1.1604\tLoss_G: 1.1371\n",
            "[2/20][2000/3750]\tLoss_D: 1.5704\tLoss_G: 0.9668\n",
            "[2/20][2100/3750]\tLoss_D: 1.1150\tLoss_G: 1.1846\n",
            "[2/20][2200/3750]\tLoss_D: 1.1972\tLoss_G: 1.3424\n",
            "[2/20][2300/3750]\tLoss_D: 1.0897\tLoss_G: 1.6041\n",
            "[2/20][2400/3750]\tLoss_D: 1.1482\tLoss_G: 1.2174\n",
            "[2/20][2500/3750]\tLoss_D: 1.2575\tLoss_G: 1.0060\n",
            "[2/20][2600/3750]\tLoss_D: 1.0345\tLoss_G: 1.2191\n",
            "[2/20][2700/3750]\tLoss_D: 1.3245\tLoss_G: 1.0790\n",
            "[2/20][2800/3750]\tLoss_D: 1.0040\tLoss_G: 1.5381\n",
            "[2/20][2900/3750]\tLoss_D: 0.9801\tLoss_G: 1.3343\n",
            "[2/20][3000/3750]\tLoss_D: 1.0831\tLoss_G: 1.3320\n",
            "[2/20][3100/3750]\tLoss_D: 1.1516\tLoss_G: 1.4180\n",
            "[2/20][3200/3750]\tLoss_D: 1.1894\tLoss_G: 1.1695\n",
            "[2/20][3300/3750]\tLoss_D: 1.1830\tLoss_G: 1.2390\n",
            "[2/20][3400/3750]\tLoss_D: 1.2047\tLoss_G: 1.1315\n",
            "[2/20][3500/3750]\tLoss_D: 0.9271\tLoss_G: 1.2908\n",
            "[2/20][3600/3750]\tLoss_D: 1.0392\tLoss_G: 1.4941\n",
            "[2/20][3700/3750]\tLoss_D: 1.0171\tLoss_G: 1.1510\n",
            "Time taken for Epoch 2: 314.77s\n",
            "[3/20][100/3750]\tLoss_D: 0.9516\tLoss_G: 1.4042\n",
            "[3/20][200/3750]\tLoss_D: 1.0444\tLoss_G: 1.3953\n",
            "[3/20][300/3750]\tLoss_D: 1.1338\tLoss_G: 1.4406\n",
            "[3/20][400/3750]\tLoss_D: 1.1449\tLoss_G: 1.2726\n",
            "[3/20][500/3750]\tLoss_D: 1.1629\tLoss_G: 1.0877\n",
            "[3/20][600/3750]\tLoss_D: 1.0734\tLoss_G: 1.3102\n",
            "[3/20][700/3750]\tLoss_D: 1.1442\tLoss_G: 1.1012\n",
            "[3/20][800/3750]\tLoss_D: 1.0906\tLoss_G: 1.5541\n",
            "[3/20][900/3750]\tLoss_D: 1.0937\tLoss_G: 1.3570\n",
            "[3/20][1000/3750]\tLoss_D: 1.1825\tLoss_G: 1.3485\n",
            "[3/20][1100/3750]\tLoss_D: 0.8419\tLoss_G: 1.4689\n",
            "[3/20][1200/3750]\tLoss_D: 1.1848\tLoss_G: 1.2813\n",
            "[3/20][1300/3750]\tLoss_D: 1.0562\tLoss_G: 1.2187\n",
            "[3/20][1400/3750]\tLoss_D: 1.1541\tLoss_G: 1.1498\n",
            "[3/20][1500/3750]\tLoss_D: 1.0598\tLoss_G: 1.1859\n",
            "[3/20][1600/3750]\tLoss_D: 1.2219\tLoss_G: 1.0867\n",
            "[3/20][1700/3750]\tLoss_D: 1.0808\tLoss_G: 1.2489\n",
            "[3/20][1800/3750]\tLoss_D: 0.8586\tLoss_G: 1.3195\n",
            "[3/20][1900/3750]\tLoss_D: 1.0005\tLoss_G: 1.4051\n",
            "[3/20][2000/3750]\tLoss_D: 1.4345\tLoss_G: 1.1526\n",
            "[3/20][2100/3750]\tLoss_D: 1.1085\tLoss_G: 1.2502\n",
            "[3/20][2200/3750]\tLoss_D: 1.2616\tLoss_G: 1.3134\n",
            "[3/20][2300/3750]\tLoss_D: 1.0259\tLoss_G: 1.5204\n",
            "[3/20][2400/3750]\tLoss_D: 1.0925\tLoss_G: 1.3368\n",
            "[3/20][2500/3750]\tLoss_D: 1.0998\tLoss_G: 1.1778\n",
            "[3/20][2600/3750]\tLoss_D: 1.0310\tLoss_G: 1.3810\n",
            "[3/20][2700/3750]\tLoss_D: 1.0115\tLoss_G: 1.4830\n",
            "[3/20][2800/3750]\tLoss_D: 0.9371\tLoss_G: 1.5666\n",
            "[3/20][2900/3750]\tLoss_D: 0.8881\tLoss_G: 1.2789\n",
            "[3/20][3000/3750]\tLoss_D: 0.9865\tLoss_G: 1.4805\n",
            "[3/20][3100/3750]\tLoss_D: 1.1083\tLoss_G: 1.4685\n",
            "[3/20][3200/3750]\tLoss_D: 1.3964\tLoss_G: 1.0321\n",
            "[3/20][3300/3750]\tLoss_D: 1.1157\tLoss_G: 1.2826\n",
            "[3/20][3400/3750]\tLoss_D: 1.1260\tLoss_G: 1.0672\n",
            "[3/20][3500/3750]\tLoss_D: 0.8169\tLoss_G: 1.3219\n",
            "[3/20][3600/3750]\tLoss_D: 0.9395\tLoss_G: 1.4397\n",
            "[3/20][3700/3750]\tLoss_D: 1.0103\tLoss_G: 1.1164\n",
            "Time taken for Epoch 3: 314.65s\n",
            "[4/20][100/3750]\tLoss_D: 1.0969\tLoss_G: 1.4973\n",
            "[4/20][200/3750]\tLoss_D: 1.0421\tLoss_G: 1.1601\n",
            "[4/20][300/3750]\tLoss_D: 1.0730\tLoss_G: 1.1388\n",
            "[4/20][400/3750]\tLoss_D: 1.1684\tLoss_G: 1.2434\n",
            "[4/20][500/3750]\tLoss_D: 0.9375\tLoss_G: 1.4546\n",
            "[4/20][600/3750]\tLoss_D: 0.9553\tLoss_G: 1.6276\n",
            "[4/20][700/3750]\tLoss_D: 1.2002\tLoss_G: 1.0240\n",
            "[4/20][800/3750]\tLoss_D: 0.8759\tLoss_G: 1.3003\n",
            "[4/20][900/3750]\tLoss_D: 0.8555\tLoss_G: 1.3446\n",
            "[4/20][1000/3750]\tLoss_D: 1.1286\tLoss_G: 1.3451\n",
            "[4/20][1100/3750]\tLoss_D: 0.8814\tLoss_G: 1.2268\n",
            "[4/20][1200/3750]\tLoss_D: 0.9297\tLoss_G: 1.4750\n",
            "[4/20][1300/3750]\tLoss_D: 1.0260\tLoss_G: 1.1906\n",
            "[4/20][1400/3750]\tLoss_D: 1.1171\tLoss_G: 1.1609\n",
            "[4/20][1500/3750]\tLoss_D: 1.1209\tLoss_G: 1.6681\n",
            "[4/20][1600/3750]\tLoss_D: 1.1056\tLoss_G: 1.1669\n",
            "[4/20][1700/3750]\tLoss_D: 1.0804\tLoss_G: 1.4286\n",
            "[4/20][1800/3750]\tLoss_D: 0.8764\tLoss_G: 1.4171\n",
            "[4/20][1900/3750]\tLoss_D: 0.7418\tLoss_G: 1.6171\n",
            "[4/20][2000/3750]\tLoss_D: 1.1551\tLoss_G: 1.2494\n",
            "[4/20][2100/3750]\tLoss_D: 1.1936\tLoss_G: 1.2594\n",
            "[4/20][2200/3750]\tLoss_D: 1.1750\tLoss_G: 1.3841\n",
            "[4/20][2300/3750]\tLoss_D: 1.1348\tLoss_G: 1.1490\n",
            "[4/20][2400/3750]\tLoss_D: 1.0749\tLoss_G: 1.4307\n",
            "[4/20][2500/3750]\tLoss_D: 1.0917\tLoss_G: 1.0957\n",
            "[4/20][2600/3750]\tLoss_D: 0.9786\tLoss_G: 1.5530\n",
            "[4/20][2700/3750]\tLoss_D: 0.9733\tLoss_G: 1.4873\n",
            "[4/20][2800/3750]\tLoss_D: 0.8017\tLoss_G: 1.7459\n",
            "[4/20][2900/3750]\tLoss_D: 0.7126\tLoss_G: 1.5673\n",
            "[4/20][3000/3750]\tLoss_D: 0.9904\tLoss_G: 1.4795\n",
            "[4/20][3100/3750]\tLoss_D: 0.8648\tLoss_G: 1.5666\n",
            "[4/20][3200/3750]\tLoss_D: 0.9833\tLoss_G: 1.2310\n",
            "[4/20][3300/3750]\tLoss_D: 1.0429\tLoss_G: 1.3022\n",
            "[4/20][3400/3750]\tLoss_D: 0.9181\tLoss_G: 1.4139\n",
            "[4/20][3500/3750]\tLoss_D: 0.5951\tLoss_G: 1.4419\n",
            "[4/20][3600/3750]\tLoss_D: 0.9002\tLoss_G: 1.5623\n",
            "[4/20][3700/3750]\tLoss_D: 1.0413\tLoss_G: 1.3526\n",
            "Time taken for Epoch 4: 314.60s\n",
            "[5/20][100/3750]\tLoss_D: 0.8680\tLoss_G: 1.6852\n",
            "[5/20][200/3750]\tLoss_D: 0.8350\tLoss_G: 1.7186\n",
            "[5/20][300/3750]\tLoss_D: 0.7047\tLoss_G: 1.8033\n",
            "[5/20][400/3750]\tLoss_D: 0.9148\tLoss_G: 1.3672\n",
            "[5/20][500/3750]\tLoss_D: 1.0159\tLoss_G: 1.3061\n",
            "[5/20][600/3750]\tLoss_D: 0.8923\tLoss_G: 1.7203\n",
            "[5/20][700/3750]\tLoss_D: 1.1960\tLoss_G: 1.0153\n",
            "[5/20][800/3750]\tLoss_D: 0.6857\tLoss_G: 1.7072\n",
            "[5/20][900/3750]\tLoss_D: 0.9033\tLoss_G: 1.4165\n",
            "[5/20][1000/3750]\tLoss_D: 1.2019\tLoss_G: 1.6226\n",
            "[5/20][1100/3750]\tLoss_D: 0.6800\tLoss_G: 1.6883\n",
            "[5/20][1200/3750]\tLoss_D: 1.1535\tLoss_G: 1.2300\n",
            "[5/20][1300/3750]\tLoss_D: 0.7310\tLoss_G: 1.7620\n",
            "[5/20][1400/3750]\tLoss_D: 0.7656\tLoss_G: 2.0333\n",
            "[5/20][1500/3750]\tLoss_D: 0.8206\tLoss_G: 1.5457\n",
            "[5/20][1600/3750]\tLoss_D: 0.9855\tLoss_G: 1.3685\n",
            "[5/20][1700/3750]\tLoss_D: 1.1222\tLoss_G: 1.3652\n",
            "[5/20][1800/3750]\tLoss_D: 0.8265\tLoss_G: 1.6505\n",
            "[5/20][1900/3750]\tLoss_D: 0.8047\tLoss_G: 1.3589\n",
            "[5/20][2000/3750]\tLoss_D: 1.2131\tLoss_G: 1.4892\n",
            "[5/20][2100/3750]\tLoss_D: 0.9326\tLoss_G: 1.5259\n",
            "[5/20][2200/3750]\tLoss_D: 0.9793\tLoss_G: 1.9105\n",
            "[5/20][2300/3750]\tLoss_D: 0.8538\tLoss_G: 1.6326\n",
            "[5/20][2400/3750]\tLoss_D: 0.6980\tLoss_G: 1.7262\n",
            "[5/20][2500/3750]\tLoss_D: 0.9350\tLoss_G: 1.4016\n",
            "[5/20][2600/3750]\tLoss_D: 1.1436\tLoss_G: 1.3096\n",
            "[5/20][2700/3750]\tLoss_D: 0.8640\tLoss_G: 1.8147\n",
            "[5/20][2800/3750]\tLoss_D: 0.8477\tLoss_G: 1.5666\n",
            "[5/20][2900/3750]\tLoss_D: 0.6799\tLoss_G: 1.7257\n",
            "[5/20][3000/3750]\tLoss_D: 0.7105\tLoss_G: 1.7737\n",
            "[5/20][3100/3750]\tLoss_D: 1.1586\tLoss_G: 1.7228\n",
            "[5/20][3200/3750]\tLoss_D: 0.9854\tLoss_G: 1.4335\n",
            "[5/20][3300/3750]\tLoss_D: 0.9401\tLoss_G: 1.3136\n",
            "[5/20][3400/3750]\tLoss_D: 0.9983\tLoss_G: 1.5379\n",
            "[5/20][3500/3750]\tLoss_D: 0.6147\tLoss_G: 1.4362\n",
            "[5/20][3600/3750]\tLoss_D: 0.5689\tLoss_G: 2.0686\n",
            "[5/20][3700/3750]\tLoss_D: 0.7106\tLoss_G: 1.6872\n",
            "Time taken for Epoch 5: 315.27s\n",
            "[6/20][100/3750]\tLoss_D: 0.6957\tLoss_G: 2.0008\n",
            "[6/20][200/3750]\tLoss_D: 0.9462\tLoss_G: 1.5536\n",
            "[6/20][300/3750]\tLoss_D: 0.7310\tLoss_G: 1.8583\n",
            "[6/20][400/3750]\tLoss_D: 0.7644\tLoss_G: 1.7433\n",
            "[6/20][500/3750]\tLoss_D: 0.8885\tLoss_G: 1.5287\n",
            "[6/20][600/3750]\tLoss_D: 0.8937\tLoss_G: 2.0462\n",
            "[6/20][700/3750]\tLoss_D: 0.6889\tLoss_G: 1.7582\n",
            "[6/20][800/3750]\tLoss_D: 0.7862\tLoss_G: 1.7032\n",
            "[6/20][900/3750]\tLoss_D: 1.0189\tLoss_G: 2.1621\n",
            "[6/20][1000/3750]\tLoss_D: 1.0634\tLoss_G: 1.7752\n",
            "[6/20][1100/3750]\tLoss_D: 0.7262\tLoss_G: 1.6595\n",
            "[6/20][1200/3750]\tLoss_D: 0.9383\tLoss_G: 1.5578\n",
            "[6/20][1300/3750]\tLoss_D: 0.6048\tLoss_G: 1.7412\n",
            "[6/20][1400/3750]\tLoss_D: 1.0344\tLoss_G: 1.3206\n",
            "[6/20][1500/3750]\tLoss_D: 0.5121\tLoss_G: 1.9237\n",
            "[6/20][1600/3750]\tLoss_D: 0.9821\tLoss_G: 1.5005\n",
            "[6/20][1700/3750]\tLoss_D: 1.0349\tLoss_G: 1.6582\n",
            "[6/20][1800/3750]\tLoss_D: 0.5431\tLoss_G: 2.0971\n",
            "[6/20][1900/3750]\tLoss_D: 0.5786\tLoss_G: 2.0866\n",
            "[6/20][2000/3750]\tLoss_D: 1.1448\tLoss_G: 1.5474\n",
            "[6/20][2100/3750]\tLoss_D: 1.1167\tLoss_G: 1.3516\n",
            "[6/20][2200/3750]\tLoss_D: 0.7937\tLoss_G: 2.0099\n",
            "[6/20][2300/3750]\tLoss_D: 0.9638\tLoss_G: 1.6312\n",
            "[6/20][2400/3750]\tLoss_D: 0.7588\tLoss_G: 1.9771\n",
            "[6/20][2500/3750]\tLoss_D: 0.8935\tLoss_G: 1.3321\n",
            "[6/20][2600/3750]\tLoss_D: 1.0262\tLoss_G: 1.6146\n",
            "[6/20][2700/3750]\tLoss_D: 0.8944\tLoss_G: 1.7226\n",
            "[6/20][2800/3750]\tLoss_D: 0.9063\tLoss_G: 2.2014\n",
            "[6/20][2900/3750]\tLoss_D: 0.4513\tLoss_G: 2.2831\n",
            "[6/20][3000/3750]\tLoss_D: 0.7302\tLoss_G: 1.6433\n",
            "[6/20][3100/3750]\tLoss_D: 0.7490\tLoss_G: 1.6364\n",
            "[6/20][3200/3750]\tLoss_D: 0.7027\tLoss_G: 1.5348\n",
            "[6/20][3300/3750]\tLoss_D: 0.8575\tLoss_G: 1.4464\n",
            "[6/20][3400/3750]\tLoss_D: 0.7949\tLoss_G: 1.6845\n",
            "[6/20][3500/3750]\tLoss_D: 0.6429\tLoss_G: 1.7281\n",
            "[6/20][3600/3750]\tLoss_D: 0.6254\tLoss_G: 1.7948\n",
            "[6/20][3700/3750]\tLoss_D: 0.6109\tLoss_G: 1.6596\n",
            "Time taken for Epoch 6: 314.50s\n",
            "[7/20][100/3750]\tLoss_D: 0.7947\tLoss_G: 1.8443\n",
            "[7/20][200/3750]\tLoss_D: 0.9386\tLoss_G: 1.3135\n",
            "[7/20][300/3750]\tLoss_D: 0.9407\tLoss_G: 1.8665\n",
            "[7/20][400/3750]\tLoss_D: 0.8101\tLoss_G: 1.3937\n",
            "[7/20][500/3750]\tLoss_D: 0.7366\tLoss_G: 2.0269\n",
            "[7/20][600/3750]\tLoss_D: 0.7468\tLoss_G: 2.0064\n",
            "[7/20][700/3750]\tLoss_D: 0.8452\tLoss_G: 1.6442\n",
            "[7/20][800/3750]\tLoss_D: 0.5956\tLoss_G: 1.8439\n",
            "[7/20][900/3750]\tLoss_D: 0.8737\tLoss_G: 2.0059\n",
            "[7/20][1000/3750]\tLoss_D: 0.7973\tLoss_G: 1.8450\n",
            "[7/20][1100/3750]\tLoss_D: 0.7895\tLoss_G: 1.6097\n",
            "[7/20][1200/3750]\tLoss_D: 0.9998\tLoss_G: 1.6101\n",
            "[7/20][1300/3750]\tLoss_D: 0.6626\tLoss_G: 1.7015\n",
            "[7/20][1400/3750]\tLoss_D: 0.7510\tLoss_G: 1.9261\n",
            "[7/20][1500/3750]\tLoss_D: 0.9014\tLoss_G: 1.5374\n",
            "[7/20][1600/3750]\tLoss_D: 0.7027\tLoss_G: 2.0452\n",
            "[7/20][1700/3750]\tLoss_D: 1.0175\tLoss_G: 1.5626\n",
            "[7/20][1800/3750]\tLoss_D: 0.4810\tLoss_G: 1.9519\n",
            "[7/20][1900/3750]\tLoss_D: 0.7705\tLoss_G: 1.7018\n",
            "[7/20][2000/3750]\tLoss_D: 0.9519\tLoss_G: 1.5251\n",
            "[7/20][2100/3750]\tLoss_D: 1.1672\tLoss_G: 1.5776\n",
            "[7/20][2200/3750]\tLoss_D: 0.5122\tLoss_G: 2.5453\n",
            "[7/20][2300/3750]\tLoss_D: 0.7517\tLoss_G: 1.7035\n",
            "[7/20][2400/3750]\tLoss_D: 0.7085\tLoss_G: 2.2354\n",
            "[7/20][2500/3750]\tLoss_D: 1.3226\tLoss_G: 1.0966\n",
            "[7/20][2600/3750]\tLoss_D: 1.3339\tLoss_G: 1.2991\n",
            "[7/20][2700/3750]\tLoss_D: 0.8804\tLoss_G: 1.9053\n",
            "[7/20][2800/3750]\tLoss_D: 0.7563\tLoss_G: 1.5979\n",
            "[7/20][2900/3750]\tLoss_D: 0.5712\tLoss_G: 2.2297\n",
            "[7/20][3000/3750]\tLoss_D: 0.7917\tLoss_G: 1.6407\n",
            "[7/20][3100/3750]\tLoss_D: 0.4855\tLoss_G: 2.1942\n",
            "[7/20][3200/3750]\tLoss_D: 0.8394\tLoss_G: 1.9843\n",
            "[7/20][3300/3750]\tLoss_D: 0.8622\tLoss_G: 1.5652\n",
            "[7/20][3400/3750]\tLoss_D: 0.7344\tLoss_G: 1.8155\n",
            "[7/20][3500/3750]\tLoss_D: 0.6393\tLoss_G: 1.6527\n",
            "[7/20][3600/3750]\tLoss_D: 0.3520\tLoss_G: 2.2839\n",
            "[7/20][3700/3750]\tLoss_D: 0.9027\tLoss_G: 1.6703\n",
            "Time taken for Epoch 7: 313.84s\n",
            "[8/20][100/3750]\tLoss_D: 0.5154\tLoss_G: 2.4619\n",
            "[8/20][200/3750]\tLoss_D: 0.8239\tLoss_G: 2.2733\n",
            "[8/20][300/3750]\tLoss_D: 0.5202\tLoss_G: 2.2969\n",
            "[8/20][400/3750]\tLoss_D: 0.8485\tLoss_G: 1.5897\n",
            "[8/20][500/3750]\tLoss_D: 0.8211\tLoss_G: 1.8058\n",
            "[8/20][600/3750]\tLoss_D: 0.5176\tLoss_G: 2.4852\n",
            "[8/20][700/3750]\tLoss_D: 1.2217\tLoss_G: 1.6087\n",
            "[8/20][800/3750]\tLoss_D: 0.6339\tLoss_G: 1.6980\n",
            "[8/20][900/3750]\tLoss_D: 0.8711\tLoss_G: 2.1771\n",
            "[8/20][1000/3750]\tLoss_D: 1.3590\tLoss_G: 1.3291\n",
            "[8/20][1100/3750]\tLoss_D: 0.4889\tLoss_G: 2.4367\n",
            "[8/20][1200/3750]\tLoss_D: 0.9783\tLoss_G: 1.9330\n",
            "[8/20][1300/3750]\tLoss_D: 0.4649\tLoss_G: 2.3974\n",
            "[8/20][1400/3750]\tLoss_D: 0.7602\tLoss_G: 1.5229\n",
            "[8/20][1500/3750]\tLoss_D: 0.4589\tLoss_G: 2.1368\n",
            "[8/20][1600/3750]\tLoss_D: 0.9030\tLoss_G: 1.7218\n",
            "[8/20][1700/3750]\tLoss_D: 0.8235\tLoss_G: 1.9762\n",
            "[8/20][1800/3750]\tLoss_D: 0.4397\tLoss_G: 2.3045\n",
            "[8/20][1900/3750]\tLoss_D: 0.7042\tLoss_G: 2.6200\n",
            "[8/20][2000/3750]\tLoss_D: 1.3441\tLoss_G: 2.0286\n",
            "[8/20][2100/3750]\tLoss_D: 0.9564\tLoss_G: 1.9970\n",
            "[8/20][2200/3750]\tLoss_D: 0.6409\tLoss_G: 2.5498\n",
            "[8/20][2300/3750]\tLoss_D: 0.7142\tLoss_G: 2.3972\n",
            "[8/20][2400/3750]\tLoss_D: 0.4864\tLoss_G: 2.4763\n",
            "[8/20][2500/3750]\tLoss_D: 0.8725\tLoss_G: 1.4547\n",
            "[8/20][2600/3750]\tLoss_D: 0.8594\tLoss_G: 2.3566\n",
            "[8/20][2700/3750]\tLoss_D: 0.7423\tLoss_G: 2.1618\n",
            "[8/20][2800/3750]\tLoss_D: 1.1226\tLoss_G: 1.8715\n",
            "[8/20][2900/3750]\tLoss_D: 0.5213\tLoss_G: 2.4198\n",
            "[8/20][3000/3750]\tLoss_D: 0.6333\tLoss_G: 2.5426\n",
            "[8/20][3100/3750]\tLoss_D: 0.4034\tLoss_G: 2.4633\n",
            "[8/20][3200/3750]\tLoss_D: 0.5168\tLoss_G: 2.0678\n",
            "[8/20][3300/3750]\tLoss_D: 0.7643\tLoss_G: 2.0313\n",
            "[8/20][3400/3750]\tLoss_D: 0.4705\tLoss_G: 2.2346\n",
            "[8/20][3500/3750]\tLoss_D: 0.5408\tLoss_G: 2.1568\n",
            "[8/20][3600/3750]\tLoss_D: 0.4867\tLoss_G: 2.2867\n",
            "[8/20][3700/3750]\tLoss_D: 0.6828\tLoss_G: 2.0447\n",
            "Time taken for Epoch 8: 313.80s\n",
            "[9/20][100/3750]\tLoss_D: 0.8233\tLoss_G: 2.0213\n",
            "[9/20][200/3750]\tLoss_D: 0.6257\tLoss_G: 2.1201\n",
            "[9/20][300/3750]\tLoss_D: 0.6029\tLoss_G: 2.6590\n",
            "[9/20][400/3750]\tLoss_D: 0.9275\tLoss_G: 1.7157\n",
            "[9/20][500/3750]\tLoss_D: 1.0812\tLoss_G: 1.6751\n",
            "[9/20][600/3750]\tLoss_D: 0.6458\tLoss_G: 2.1385\n",
            "[9/20][700/3750]\tLoss_D: 1.2060\tLoss_G: 1.6189\n",
            "[9/20][800/3750]\tLoss_D: 0.4497\tLoss_G: 2.2775\n",
            "[9/20][900/3750]\tLoss_D: 0.8954\tLoss_G: 1.7969\n",
            "[9/20][1000/3750]\tLoss_D: 0.9457\tLoss_G: 1.8190\n",
            "[9/20][1100/3750]\tLoss_D: 0.7564\tLoss_G: 1.8976\n",
            "[9/20][1200/3750]\tLoss_D: 0.8964\tLoss_G: 1.9644\n",
            "[9/20][1300/3750]\tLoss_D: 0.4953\tLoss_G: 2.4713\n",
            "[9/20][1400/3750]\tLoss_D: 1.1051\tLoss_G: 1.4160\n",
            "[9/20][1500/3750]\tLoss_D: 0.7228\tLoss_G: 1.7855\n",
            "[9/20][1600/3750]\tLoss_D: 0.6542\tLoss_G: 2.0432\n",
            "[9/20][1700/3750]\tLoss_D: 0.3491\tLoss_G: 2.5829\n",
            "[9/20][1800/3750]\tLoss_D: 0.3788\tLoss_G: 2.8276\n",
            "[9/20][1900/3750]\tLoss_D: 0.6504\tLoss_G: 2.1957\n",
            "[9/20][2000/3750]\tLoss_D: 1.1320\tLoss_G: 1.5771\n",
            "[9/20][2100/3750]\tLoss_D: 0.6661\tLoss_G: 2.1452\n",
            "[9/20][2200/3750]\tLoss_D: 0.3877\tLoss_G: 2.4039\n",
            "[9/20][2300/3750]\tLoss_D: 0.4368\tLoss_G: 2.5322\n",
            "[9/20][2400/3750]\tLoss_D: 0.5514\tLoss_G: 2.1594\n",
            "[9/20][2500/3750]\tLoss_D: 0.8227\tLoss_G: 1.6150\n",
            "[9/20][2600/3750]\tLoss_D: 1.1759\tLoss_G: 2.1869\n",
            "[9/20][2700/3750]\tLoss_D: 0.6762\tLoss_G: 1.8657\n",
            "[9/20][2800/3750]\tLoss_D: 0.6415\tLoss_G: 2.4193\n",
            "[9/20][2900/3750]\tLoss_D: 0.3463\tLoss_G: 3.0045\n",
            "[9/20][3000/3750]\tLoss_D: 0.8923\tLoss_G: 2.9384\n",
            "[9/20][3100/3750]\tLoss_D: 0.6492\tLoss_G: 2.3055\n",
            "[9/20][3200/3750]\tLoss_D: 0.6006\tLoss_G: 1.8769\n",
            "[9/20][3300/3750]\tLoss_D: 0.6136\tLoss_G: 2.3816\n",
            "[9/20][3400/3750]\tLoss_D: 0.6107\tLoss_G: 2.7378\n",
            "[9/20][3500/3750]\tLoss_D: 0.5378\tLoss_G: 2.5117\n",
            "[9/20][3600/3750]\tLoss_D: 0.4195\tLoss_G: 2.7910\n",
            "[9/20][3700/3750]\tLoss_D: 0.4719\tLoss_G: 2.4149\n",
            "Time taken for Epoch 9: 313.73s\n",
            "[10/20][100/3750]\tLoss_D: 0.5230\tLoss_G: 2.7486\n",
            "[10/20][200/3750]\tLoss_D: 0.4403\tLoss_G: 2.4524\n",
            "[10/20][300/3750]\tLoss_D: 0.5358\tLoss_G: 2.5329\n",
            "[10/20][400/3750]\tLoss_D: 0.6424\tLoss_G: 1.9364\n",
            "[10/20][500/3750]\tLoss_D: 0.9787\tLoss_G: 1.9467\n",
            "[10/20][600/3750]\tLoss_D: 0.6846\tLoss_G: 2.4340\n",
            "[10/20][700/3750]\tLoss_D: 0.8146\tLoss_G: 2.4447\n",
            "[10/20][800/3750]\tLoss_D: 0.6584\tLoss_G: 2.0019\n",
            "[10/20][900/3750]\tLoss_D: 1.0474\tLoss_G: 1.6749\n",
            "[10/20][1000/3750]\tLoss_D: 0.5151\tLoss_G: 2.7940\n",
            "[10/20][1100/3750]\tLoss_D: 0.8628\tLoss_G: 2.0624\n",
            "[10/20][1200/3750]\tLoss_D: 0.8803\tLoss_G: 3.0357\n",
            "[10/20][1300/3750]\tLoss_D: 0.6775\tLoss_G: 2.4288\n",
            "[10/20][1400/3750]\tLoss_D: 0.9288\tLoss_G: 1.7409\n",
            "[10/20][1500/3750]\tLoss_D: 0.3675\tLoss_G: 2.1772\n",
            "[10/20][1600/3750]\tLoss_D: 0.6832\tLoss_G: 2.1098\n",
            "[10/20][1700/3750]\tLoss_D: 0.6124\tLoss_G: 2.3564\n",
            "[10/20][1800/3750]\tLoss_D: 0.2634\tLoss_G: 3.6520\n",
            "[10/20][1900/3750]\tLoss_D: 0.3283\tLoss_G: 3.2791\n",
            "[10/20][2000/3750]\tLoss_D: 1.2964\tLoss_G: 1.8801\n",
            "[10/20][2100/3750]\tLoss_D: 0.6211\tLoss_G: 2.2985\n",
            "[10/20][2200/3750]\tLoss_D: 0.4798\tLoss_G: 2.5186\n",
            "[10/20][2300/3750]\tLoss_D: 0.6730\tLoss_G: 2.0337\n",
            "[10/20][2400/3750]\tLoss_D: 0.4221\tLoss_G: 2.5993\n",
            "[10/20][2500/3750]\tLoss_D: 0.5539\tLoss_G: 2.5252\n",
            "[10/20][2600/3750]\tLoss_D: 0.7052\tLoss_G: 2.2681\n",
            "[10/20][2700/3750]\tLoss_D: 0.5553\tLoss_G: 2.4359\n",
            "[10/20][2800/3750]\tLoss_D: 0.3212\tLoss_G: 2.6914\n",
            "[10/20][2900/3750]\tLoss_D: 0.6844\tLoss_G: 2.5782\n",
            "[10/20][3000/3750]\tLoss_D: 0.3852\tLoss_G: 2.5186\n",
            "[10/20][3100/3750]\tLoss_D: 0.6119\tLoss_G: 1.9151\n",
            "[10/20][3200/3750]\tLoss_D: 0.8599\tLoss_G: 1.9124\n",
            "[10/20][3300/3750]\tLoss_D: 0.7008\tLoss_G: 1.7762\n",
            "[10/20][3400/3750]\tLoss_D: 0.5129\tLoss_G: 2.9422\n",
            "[10/20][3500/3750]\tLoss_D: 0.5383\tLoss_G: 2.2093\n",
            "[10/20][3600/3750]\tLoss_D: 0.2929\tLoss_G: 3.1522\n",
            "[10/20][3700/3750]\tLoss_D: 0.4043\tLoss_G: 2.8260\n",
            "Time taken for Epoch 10: 313.52s\n",
            "[11/20][100/3750]\tLoss_D: 1.2592\tLoss_G: 1.8748\n",
            "[11/20][200/3750]\tLoss_D: 0.4319\tLoss_G: 2.9238\n",
            "[11/20][300/3750]\tLoss_D: 0.5207\tLoss_G: 2.9728\n",
            "[11/20][400/3750]\tLoss_D: 0.5859\tLoss_G: 2.1985\n",
            "[11/20][500/3750]\tLoss_D: 1.0148\tLoss_G: 2.7172\n",
            "[11/20][600/3750]\tLoss_D: 0.5812\tLoss_G: 2.8788\n",
            "[11/20][700/3750]\tLoss_D: 0.6782\tLoss_G: 2.2791\n",
            "[11/20][800/3750]\tLoss_D: 0.3163\tLoss_G: 3.5253\n",
            "[11/20][900/3750]\tLoss_D: 0.5493\tLoss_G: 2.5153\n",
            "[11/20][1000/3750]\tLoss_D: 0.8716\tLoss_G: 2.1110\n",
            "[11/20][1100/3750]\tLoss_D: 0.3300\tLoss_G: 2.4554\n",
            "[11/20][1200/3750]\tLoss_D: 0.8525\tLoss_G: 2.1284\n",
            "[11/20][1300/3750]\tLoss_D: 0.3867\tLoss_G: 2.7530\n",
            "[11/20][1400/3750]\tLoss_D: 0.6454\tLoss_G: 2.0112\n",
            "[11/20][1500/3750]\tLoss_D: 0.5052\tLoss_G: 1.8137\n",
            "[11/20][1600/3750]\tLoss_D: 0.6757\tLoss_G: 2.1741\n",
            "[11/20][1700/3750]\tLoss_D: 0.6854\tLoss_G: 2.5310\n",
            "[11/20][1800/3750]\tLoss_D: 0.5317\tLoss_G: 2.3976\n",
            "[11/20][1900/3750]\tLoss_D: 0.1482\tLoss_G: 3.4093\n",
            "[11/20][2000/3750]\tLoss_D: 0.7327\tLoss_G: 2.0604\n",
            "[11/20][2100/3750]\tLoss_D: 0.3966\tLoss_G: 2.6916\n",
            "[11/20][2200/3750]\tLoss_D: 0.3738\tLoss_G: 2.5971\n",
            "[11/20][2300/3750]\tLoss_D: 0.4644\tLoss_G: 2.6797\n",
            "[11/20][2400/3750]\tLoss_D: 0.5028\tLoss_G: 2.6277\n",
            "[11/20][2500/3750]\tLoss_D: 1.4344\tLoss_G: 1.5459\n",
            "[11/20][2600/3750]\tLoss_D: 0.6932\tLoss_G: 2.2338\n",
            "[11/20][2700/3750]\tLoss_D: 0.7611\tLoss_G: 2.5869\n",
            "[11/20][2800/3750]\tLoss_D: 0.6250\tLoss_G: 2.4206\n",
            "[11/20][2900/3750]\tLoss_D: 0.4245\tLoss_G: 2.7555\n",
            "[11/20][3000/3750]\tLoss_D: 0.5372\tLoss_G: 2.7367\n",
            "[11/20][3100/3750]\tLoss_D: 0.6194\tLoss_G: 1.8039\n",
            "[11/20][3200/3750]\tLoss_D: 0.4312\tLoss_G: 2.7250\n",
            "[11/20][3300/3750]\tLoss_D: 0.3071\tLoss_G: 2.9533\n",
            "[11/20][3400/3750]\tLoss_D: 0.7166\tLoss_G: 2.5485\n",
            "[11/20][3500/3750]\tLoss_D: 0.5364\tLoss_G: 3.2617\n",
            "[11/20][3600/3750]\tLoss_D: 0.4004\tLoss_G: 2.4101\n",
            "[11/20][3700/3750]\tLoss_D: 0.4959\tLoss_G: 2.8827\n",
            "Time taken for Epoch 11: 313.78s\n",
            "[12/20][100/3750]\tLoss_D: 0.5501\tLoss_G: 2.6541\n",
            "[12/20][200/3750]\tLoss_D: 0.3181\tLoss_G: 2.7734\n",
            "[12/20][300/3750]\tLoss_D: 0.3513\tLoss_G: 3.3358\n",
            "[12/20][400/3750]\tLoss_D: 0.5439\tLoss_G: 2.4992\n",
            "[12/20][500/3750]\tLoss_D: 0.8888\tLoss_G: 2.8248\n",
            "[12/20][600/3750]\tLoss_D: 0.3870\tLoss_G: 3.6276\n",
            "[12/20][700/3750]\tLoss_D: 0.7602\tLoss_G: 2.0195\n",
            "[12/20][800/3750]\tLoss_D: 0.3866\tLoss_G: 2.8624\n",
            "[12/20][900/3750]\tLoss_D: 0.7729\tLoss_G: 2.2952\n",
            "[12/20][1000/3750]\tLoss_D: 0.9421\tLoss_G: 2.0750\n",
            "[12/20][1100/3750]\tLoss_D: 0.8476\tLoss_G: 3.0225\n",
            "[12/20][1200/3750]\tLoss_D: 0.8719\tLoss_G: 2.3917\n",
            "[12/20][1300/3750]\tLoss_D: 1.3141\tLoss_G: 2.7642\n",
            "[12/20][1400/3750]\tLoss_D: 0.3803\tLoss_G: 2.7230\n",
            "[12/20][1500/3750]\tLoss_D: 0.7549\tLoss_G: 1.8726\n",
            "[12/20][1600/3750]\tLoss_D: 0.5469\tLoss_G: 2.5247\n",
            "[12/20][1700/3750]\tLoss_D: 0.3941\tLoss_G: 3.2241\n",
            "[12/20][1800/3750]\tLoss_D: 0.3765\tLoss_G: 2.8051\n",
            "[12/20][1900/3750]\tLoss_D: 0.2608\tLoss_G: 3.3912\n",
            "[12/20][2000/3750]\tLoss_D: 0.5283\tLoss_G: 2.7482\n",
            "[12/20][2100/3750]\tLoss_D: 0.5000\tLoss_G: 2.5535\n",
            "[12/20][2200/3750]\tLoss_D: 0.4042\tLoss_G: 3.6487\n",
            "[12/20][2300/3750]\tLoss_D: 0.5889\tLoss_G: 2.9360\n",
            "[12/20][2400/3750]\tLoss_D: 0.6249\tLoss_G: 2.4002\n",
            "[12/20][2500/3750]\tLoss_D: 0.7814\tLoss_G: 2.4491\n",
            "[12/20][2600/3750]\tLoss_D: 0.8418\tLoss_G: 2.0627\n",
            "[12/20][2700/3750]\tLoss_D: 0.4012\tLoss_G: 2.6405\n",
            "[12/20][2800/3750]\tLoss_D: 0.3450\tLoss_G: 2.7294\n",
            "[12/20][2900/3750]\tLoss_D: 0.4096\tLoss_G: 2.6273\n",
            "[12/20][3000/3750]\tLoss_D: 0.6527\tLoss_G: 2.2357\n",
            "[12/20][3100/3750]\tLoss_D: 0.7158\tLoss_G: 3.2412\n",
            "[12/20][3200/3750]\tLoss_D: 0.5899\tLoss_G: 2.3776\n",
            "[12/20][3300/3750]\tLoss_D: 0.2554\tLoss_G: 3.0898\n",
            "[12/20][3400/3750]\tLoss_D: 0.4895\tLoss_G: 2.7592\n",
            "[12/20][3500/3750]\tLoss_D: 0.6195\tLoss_G: 2.3051\n",
            "[12/20][3600/3750]\tLoss_D: 0.2786\tLoss_G: 2.9018\n",
            "[12/20][3700/3750]\tLoss_D: 0.4595\tLoss_G: 2.6528\n",
            "Time taken for Epoch 12: 313.69s\n",
            "[13/20][100/3750]\tLoss_D: 0.5404\tLoss_G: 2.6390\n",
            "[13/20][200/3750]\tLoss_D: 0.6693\tLoss_G: 2.3871\n",
            "[13/20][300/3750]\tLoss_D: 0.3447\tLoss_G: 3.0986\n",
            "[13/20][400/3750]\tLoss_D: 0.8997\tLoss_G: 2.2632\n",
            "[13/20][500/3750]\tLoss_D: 0.4667\tLoss_G: 2.4765\n",
            "[13/20][600/3750]\tLoss_D: 0.7480\tLoss_G: 2.6796\n",
            "[13/20][700/3750]\tLoss_D: 0.7179\tLoss_G: 2.5340\n",
            "[13/20][800/3750]\tLoss_D: 0.6065\tLoss_G: 2.4218\n",
            "[13/20][900/3750]\tLoss_D: 0.9891\tLoss_G: 1.6305\n",
            "[13/20][1000/3750]\tLoss_D: 0.6804\tLoss_G: 2.7328\n",
            "[13/20][1100/3750]\tLoss_D: 0.3493\tLoss_G: 2.4344\n",
            "[13/20][1200/3750]\tLoss_D: 0.7494\tLoss_G: 2.1539\n",
            "[13/20][1300/3750]\tLoss_D: 0.4964\tLoss_G: 2.7908\n",
            "[13/20][1400/3750]\tLoss_D: 0.4084\tLoss_G: 2.7690\n",
            "[13/20][1500/3750]\tLoss_D: 0.3466\tLoss_G: 2.6785\n",
            "[13/20][1600/3750]\tLoss_D: 0.5191\tLoss_G: 2.8276\n",
            "[13/20][1700/3750]\tLoss_D: 0.2337\tLoss_G: 4.1564\n",
            "[13/20][1800/3750]\tLoss_D: 0.5662\tLoss_G: 2.9956\n",
            "[13/20][1900/3750]\tLoss_D: 0.2988\tLoss_G: 3.0314\n",
            "[13/20][2000/3750]\tLoss_D: 0.6686\tLoss_G: 2.8183\n",
            "[13/20][2100/3750]\tLoss_D: 0.5482\tLoss_G: 3.4089\n",
            "[13/20][2200/3750]\tLoss_D: 0.2868\tLoss_G: 3.6043\n",
            "[13/20][2300/3750]\tLoss_D: 0.5497\tLoss_G: 2.8467\n",
            "[13/20][2400/3750]\tLoss_D: 0.5015\tLoss_G: 2.8943\n",
            "[13/20][2500/3750]\tLoss_D: 0.6835\tLoss_G: 2.1110\n",
            "[13/20][2600/3750]\tLoss_D: 0.5225\tLoss_G: 2.9629\n",
            "[13/20][2700/3750]\tLoss_D: 0.2864\tLoss_G: 3.0018\n",
            "[13/20][2800/3750]\tLoss_D: 0.2600\tLoss_G: 2.6597\n",
            "[13/20][2900/3750]\tLoss_D: 0.3882\tLoss_G: 2.8556\n",
            "[13/20][3000/3750]\tLoss_D: 0.3940\tLoss_G: 2.6065\n",
            "[13/20][3100/3750]\tLoss_D: 0.9804\tLoss_G: 2.1536\n",
            "[13/20][3200/3750]\tLoss_D: 0.2824\tLoss_G: 2.3118\n",
            "[13/20][3300/3750]\tLoss_D: 0.3539\tLoss_G: 2.5934\n",
            "[13/20][3400/3750]\tLoss_D: 0.5380\tLoss_G: 3.5843\n",
            "[13/20][3500/3750]\tLoss_D: 0.3592\tLoss_G: 3.2468\n",
            "[13/20][3600/3750]\tLoss_D: 0.1941\tLoss_G: 3.0668\n",
            "[13/20][3700/3750]\tLoss_D: 0.3431\tLoss_G: 3.3613\n",
            "Time taken for Epoch 13: 313.57s\n",
            "[14/20][100/3750]\tLoss_D: 0.3056\tLoss_G: 3.3626\n",
            "[14/20][200/3750]\tLoss_D: 0.3745\tLoss_G: 3.8075\n",
            "[14/20][300/3750]\tLoss_D: 0.2490\tLoss_G: 3.1520\n",
            "[14/20][400/3750]\tLoss_D: 0.5410\tLoss_G: 2.1372\n",
            "[14/20][500/3750]\tLoss_D: 0.7152\tLoss_G: 2.4994\n",
            "[14/20][600/3750]\tLoss_D: 0.5600\tLoss_G: 3.2028\n",
            "[14/20][700/3750]\tLoss_D: 0.3807\tLoss_G: 3.2621\n",
            "[14/20][800/3750]\tLoss_D: 0.2860\tLoss_G: 2.8896\n",
            "[14/20][900/3750]\tLoss_D: 0.4086\tLoss_G: 2.5986\n",
            "[14/20][1000/3750]\tLoss_D: 0.6389\tLoss_G: 2.9100\n",
            "[14/20][1100/3750]\tLoss_D: 0.4020\tLoss_G: 3.0662\n",
            "[14/20][1200/3750]\tLoss_D: 1.0586\tLoss_G: 2.5905\n",
            "[14/20][1300/3750]\tLoss_D: 0.7827\tLoss_G: 2.1467\n",
            "[14/20][1400/3750]\tLoss_D: 0.6017\tLoss_G: 2.5644\n",
            "[14/20][1500/3750]\tLoss_D: 0.8677\tLoss_G: 2.9711\n",
            "[14/20][1600/3750]\tLoss_D: 0.2950\tLoss_G: 3.2021\n",
            "[14/20][1700/3750]\tLoss_D: 0.3374\tLoss_G: 3.3836\n",
            "[14/20][1800/3750]\tLoss_D: 0.2260\tLoss_G: 3.6170\n",
            "[14/20][1900/3750]\tLoss_D: 0.5086\tLoss_G: 3.3366\n",
            "[14/20][2000/3750]\tLoss_D: 0.8674\tLoss_G: 2.0448\n",
            "[14/20][2100/3750]\tLoss_D: 0.5233\tLoss_G: 2.5109\n",
            "[14/20][2200/3750]\tLoss_D: 0.3140\tLoss_G: 3.1036\n",
            "[14/20][2300/3750]\tLoss_D: 0.2291\tLoss_G: 4.0024\n",
            "[14/20][2400/3750]\tLoss_D: 0.4158\tLoss_G: 3.0695\n",
            "[14/20][2500/3750]\tLoss_D: 0.5431\tLoss_G: 2.6868\n",
            "[14/20][2600/3750]\tLoss_D: 0.5536\tLoss_G: 2.6763\n",
            "[14/20][2700/3750]\tLoss_D: 0.1591\tLoss_G: 3.6945\n",
            "[14/20][2800/3750]\tLoss_D: 0.4095\tLoss_G: 3.2214\n",
            "[14/20][2900/3750]\tLoss_D: 0.3711\tLoss_G: 3.0846\n",
            "[14/20][3000/3750]\tLoss_D: 0.6228\tLoss_G: 2.7209\n",
            "[14/20][3100/3750]\tLoss_D: 0.2205\tLoss_G: 3.2621\n",
            "[14/20][3200/3750]\tLoss_D: 0.7996\tLoss_G: 2.8448\n",
            "[14/20][3300/3750]\tLoss_D: 0.4231\tLoss_G: 2.8259\n",
            "[14/20][3400/3750]\tLoss_D: 0.8213\tLoss_G: 3.1106\n",
            "[14/20][3500/3750]\tLoss_D: 0.6939\tLoss_G: 2.2577\n",
            "[14/20][3600/3750]\tLoss_D: 0.2272\tLoss_G: 3.5827\n",
            "[14/20][3700/3750]\tLoss_D: 0.2449\tLoss_G: 3.3079\n",
            "Time taken for Epoch 14: 313.73s\n",
            "[15/20][100/3750]\tLoss_D: 0.6711\tLoss_G: 2.7126\n",
            "[15/20][200/3750]\tLoss_D: 0.4020\tLoss_G: 2.8078\n",
            "[15/20][300/3750]\tLoss_D: 0.1755\tLoss_G: 3.7603\n",
            "[15/20][400/3750]\tLoss_D: 0.4613\tLoss_G: 3.2402\n",
            "[15/20][500/3750]\tLoss_D: 0.6309\tLoss_G: 2.7933\n",
            "[15/20][600/3750]\tLoss_D: 0.3638\tLoss_G: 3.8213\n",
            "[15/20][700/3750]\tLoss_D: 0.6505\tLoss_G: 3.2713\n",
            "[15/20][800/3750]\tLoss_D: 0.3222\tLoss_G: 2.6643\n",
            "[15/20][900/3750]\tLoss_D: 0.6511\tLoss_G: 2.2199\n",
            "[15/20][1000/3750]\tLoss_D: 0.4246\tLoss_G: 4.0050\n",
            "[15/20][1100/3750]\tLoss_D: 0.2979\tLoss_G: 3.2892\n",
            "[15/20][1200/3750]\tLoss_D: 0.7355\tLoss_G: 2.5979\n",
            "[15/20][1300/3750]\tLoss_D: 0.5346\tLoss_G: 3.3703\n",
            "[15/20][1400/3750]\tLoss_D: 0.6314\tLoss_G: 2.4260\n",
            "[15/20][1500/3750]\tLoss_D: 1.2076\tLoss_G: 3.6598\n",
            "[15/20][1600/3750]\tLoss_D: 0.2255\tLoss_G: 3.4614\n",
            "[15/20][1700/3750]\tLoss_D: 0.3922\tLoss_G: 2.5158\n",
            "[15/20][1800/3750]\tLoss_D: 0.2702\tLoss_G: 3.6740\n",
            "[15/20][1900/3750]\tLoss_D: 0.2622\tLoss_G: 3.1846\n",
            "[15/20][2000/3750]\tLoss_D: 0.3779\tLoss_G: 2.4868\n",
            "[15/20][2100/3750]\tLoss_D: 0.3044\tLoss_G: 3.1313\n",
            "[15/20][2200/3750]\tLoss_D: 0.1739\tLoss_G: 4.1478\n",
            "[15/20][2300/3750]\tLoss_D: 0.3744\tLoss_G: 2.8849\n",
            "[15/20][2400/3750]\tLoss_D: 0.4626\tLoss_G: 3.2619\n",
            "[15/20][2500/3750]\tLoss_D: 0.4951\tLoss_G: 2.8717\n",
            "[15/20][2600/3750]\tLoss_D: 0.3529\tLoss_G: 3.8510\n",
            "[15/20][2700/3750]\tLoss_D: 0.4385\tLoss_G: 3.3085\n",
            "[15/20][2800/3750]\tLoss_D: 0.1644\tLoss_G: 3.2578\n",
            "[15/20][2900/3750]\tLoss_D: 0.2322\tLoss_G: 3.9324\n",
            "[15/20][3000/3750]\tLoss_D: 0.7626\tLoss_G: 3.2097\n",
            "[15/20][3100/3750]\tLoss_D: 0.4781\tLoss_G: 2.4097\n",
            "[15/20][3200/3750]\tLoss_D: 1.0457\tLoss_G: 1.6443\n",
            "[15/20][3300/3750]\tLoss_D: 0.6042\tLoss_G: 2.5501\n",
            "[15/20][3400/3750]\tLoss_D: 0.3688\tLoss_G: 3.2097\n",
            "[15/20][3500/3750]\tLoss_D: 0.5894\tLoss_G: 2.6322\n",
            "[15/20][3600/3750]\tLoss_D: 0.2011\tLoss_G: 3.2441\n",
            "[15/20][3700/3750]\tLoss_D: 0.3072\tLoss_G: 3.0605\n",
            "Time taken for Epoch 15: 314.25s\n",
            "[16/20][100/3750]\tLoss_D: 0.3386\tLoss_G: 3.4437\n",
            "[16/20][200/3750]\tLoss_D: 0.3013\tLoss_G: 2.9921\n",
            "[16/20][300/3750]\tLoss_D: 0.2469\tLoss_G: 3.7699\n",
            "[16/20][400/3750]\tLoss_D: 0.6819\tLoss_G: 3.7132\n",
            "[16/20][500/3750]\tLoss_D: 0.8203\tLoss_G: 2.3025\n",
            "[16/20][600/3750]\tLoss_D: 0.4363\tLoss_G: 2.9097\n",
            "[16/20][700/3750]\tLoss_D: 0.5557\tLoss_G: 3.5285\n",
            "[16/20][800/3750]\tLoss_D: 0.3524\tLoss_G: 3.5571\n",
            "[16/20][900/3750]\tLoss_D: 0.3249\tLoss_G: 3.0819\n",
            "[16/20][1000/3750]\tLoss_D: 0.6487\tLoss_G: 2.5227\n",
            "[16/20][1100/3750]\tLoss_D: 0.3343\tLoss_G: 2.5236\n",
            "[16/20][1200/3750]\tLoss_D: 0.7679\tLoss_G: 2.6767\n",
            "[16/20][1300/3750]\tLoss_D: 0.6253\tLoss_G: 2.8433\n",
            "[16/20][1400/3750]\tLoss_D: 0.4387\tLoss_G: 2.5174\n",
            "[16/20][1500/3750]\tLoss_D: 0.3258\tLoss_G: 2.5537\n",
            "[16/20][1600/3750]\tLoss_D: 0.3854\tLoss_G: 3.0020\n",
            "[16/20][1700/3750]\tLoss_D: 0.7073\tLoss_G: 3.4122\n",
            "[16/20][1800/3750]\tLoss_D: 0.0968\tLoss_G: 4.3876\n",
            "[16/20][1900/3750]\tLoss_D: 0.4147\tLoss_G: 3.1184\n",
            "[16/20][2000/3750]\tLoss_D: 0.8273\tLoss_G: 3.9299\n",
            "[16/20][2100/3750]\tLoss_D: 0.3758\tLoss_G: 2.5948\n",
            "[16/20][2200/3750]\tLoss_D: 0.1315\tLoss_G: 3.6329\n",
            "[16/20][2300/3750]\tLoss_D: 0.4645\tLoss_G: 3.1339\n",
            "[16/20][2400/3750]\tLoss_D: 0.7242\tLoss_G: 3.9817\n",
            "[16/20][2500/3750]\tLoss_D: 0.5990\tLoss_G: 3.2822\n",
            "[16/20][2600/3750]\tLoss_D: 0.6271\tLoss_G: 3.3659\n",
            "[16/20][2700/3750]\tLoss_D: 0.3695\tLoss_G: 3.6964\n",
            "[16/20][2800/3750]\tLoss_D: 0.3570\tLoss_G: 3.0642\n",
            "[16/20][2900/3750]\tLoss_D: 0.4487\tLoss_G: 3.8054\n",
            "[16/20][3000/3750]\tLoss_D: 0.3657\tLoss_G: 3.5261\n",
            "[16/20][3100/3750]\tLoss_D: 0.3903\tLoss_G: 3.9905\n",
            "[16/20][3200/3750]\tLoss_D: 0.2467\tLoss_G: 3.1074\n",
            "[16/20][3300/3750]\tLoss_D: 0.4261\tLoss_G: 2.8286\n",
            "[16/20][3400/3750]\tLoss_D: 0.7258\tLoss_G: 2.7496\n",
            "[16/20][3500/3750]\tLoss_D: 0.4379\tLoss_G: 2.2706\n",
            "[16/20][3600/3750]\tLoss_D: 0.3715\tLoss_G: 2.8881\n",
            "[16/20][3700/3750]\tLoss_D: 0.1579\tLoss_G: 4.0052\n",
            "Time taken for Epoch 16: 313.94s\n",
            "[17/20][100/3750]\tLoss_D: 0.2887\tLoss_G: 3.4581\n",
            "[17/20][200/3750]\tLoss_D: 0.2685\tLoss_G: 3.3450\n",
            "[17/20][300/3750]\tLoss_D: 0.2320\tLoss_G: 4.4523\n",
            "[17/20][400/3750]\tLoss_D: 0.5695\tLoss_G: 2.8525\n",
            "[17/20][500/3750]\tLoss_D: 0.6138\tLoss_G: 2.9522\n",
            "[17/20][600/3750]\tLoss_D: 0.1610\tLoss_G: 4.0387\n",
            "[17/20][700/3750]\tLoss_D: 0.4224\tLoss_G: 3.9084\n",
            "[17/20][800/3750]\tLoss_D: 0.5494\tLoss_G: 2.9648\n",
            "[17/20][900/3750]\tLoss_D: 0.4221\tLoss_G: 3.7474\n",
            "[17/20][1000/3750]\tLoss_D: 0.3599\tLoss_G: 2.8697\n",
            "[17/20][1100/3750]\tLoss_D: 0.3021\tLoss_G: 3.8077\n",
            "[17/20][1200/3750]\tLoss_D: 0.6797\tLoss_G: 2.1654\n",
            "[17/20][1300/3750]\tLoss_D: 0.5497\tLoss_G: 2.9490\n",
            "[17/20][1400/3750]\tLoss_D: 0.5445\tLoss_G: 2.7848\n",
            "[17/20][1500/3750]\tLoss_D: 0.7484\tLoss_G: 4.5407\n",
            "[17/20][1600/3750]\tLoss_D: 0.4852\tLoss_G: 3.0445\n",
            "[17/20][1700/3750]\tLoss_D: 0.3528\tLoss_G: 3.4992\n",
            "[17/20][1800/3750]\tLoss_D: 0.2424\tLoss_G: 3.8792\n",
            "[17/20][1900/3750]\tLoss_D: 0.3114\tLoss_G: 3.0107\n",
            "[17/20][2000/3750]\tLoss_D: 0.5659\tLoss_G: 2.5907\n",
            "[17/20][2100/3750]\tLoss_D: 0.6221\tLoss_G: 2.9491\n",
            "[17/20][2200/3750]\tLoss_D: 0.3381\tLoss_G: 3.6646\n",
            "[17/20][2300/3750]\tLoss_D: 0.4440\tLoss_G: 3.4210\n",
            "[17/20][2400/3750]\tLoss_D: 0.5364\tLoss_G: 2.8218\n",
            "[17/20][2500/3750]\tLoss_D: 0.6246\tLoss_G: 2.7418\n",
            "[17/20][2600/3750]\tLoss_D: 0.6047\tLoss_G: 3.3219\n",
            "[17/20][2700/3750]\tLoss_D: 0.2312\tLoss_G: 3.1940\n",
            "[17/20][2800/3750]\tLoss_D: 0.2034\tLoss_G: 3.2150\n",
            "[17/20][2900/3750]\tLoss_D: 0.4251\tLoss_G: 3.8528\n",
            "[17/20][3000/3750]\tLoss_D: 0.3246\tLoss_G: 3.2164\n",
            "[17/20][3100/3750]\tLoss_D: 0.4574\tLoss_G: 3.5184\n",
            "[17/20][3200/3750]\tLoss_D: 0.5732\tLoss_G: 2.9644\n",
            "[17/20][3300/3750]\tLoss_D: 0.1347\tLoss_G: 3.6832\n",
            "[17/20][3400/3750]\tLoss_D: 0.3618\tLoss_G: 3.6465\n",
            "[17/20][3500/3750]\tLoss_D: 0.2895\tLoss_G: 2.9750\n",
            "[17/20][3600/3750]\tLoss_D: 0.2538\tLoss_G: 4.4144\n",
            "[17/20][3700/3750]\tLoss_D: 0.2138\tLoss_G: 3.7108\n",
            "Time taken for Epoch 17: 313.81s\n",
            "[18/20][100/3750]\tLoss_D: 0.4027\tLoss_G: 3.4107\n",
            "[18/20][200/3750]\tLoss_D: 0.4118\tLoss_G: 2.4551\n",
            "[18/20][300/3750]\tLoss_D: 0.1248\tLoss_G: 4.3721\n",
            "[18/20][400/3750]\tLoss_D: 0.5639\tLoss_G: 2.6438\n",
            "[18/20][500/3750]\tLoss_D: 0.4805\tLoss_G: 3.6953\n",
            "[18/20][600/3750]\tLoss_D: 0.2296\tLoss_G: 3.8091\n",
            "[18/20][700/3750]\tLoss_D: 1.2615\tLoss_G: 2.6020\n",
            "[18/20][800/3750]\tLoss_D: 0.3435\tLoss_G: 3.5678\n",
            "[18/20][900/3750]\tLoss_D: 0.3279\tLoss_G: 3.1403\n",
            "[18/20][1000/3750]\tLoss_D: 0.3590\tLoss_G: 2.9755\n",
            "[18/20][1100/3750]\tLoss_D: 0.1317\tLoss_G: 3.2134\n",
            "[18/20][1200/3750]\tLoss_D: 0.8216\tLoss_G: 2.4319\n",
            "[18/20][1300/3750]\tLoss_D: 0.3858\tLoss_G: 3.8093\n",
            "[18/20][1400/3750]\tLoss_D: 0.3499\tLoss_G: 2.8343\n",
            "[18/20][1500/3750]\tLoss_D: 0.2732\tLoss_G: 3.3188\n",
            "[18/20][1600/3750]\tLoss_D: 0.6781\tLoss_G: 3.1469\n",
            "[18/20][1700/3750]\tLoss_D: 0.4068\tLoss_G: 3.5366\n",
            "[18/20][1800/3750]\tLoss_D: 0.8560\tLoss_G: 2.4004\n",
            "[18/20][1900/3750]\tLoss_D: 0.1118\tLoss_G: 4.4001\n",
            "[18/20][2000/3750]\tLoss_D: 0.5664\tLoss_G: 3.5303\n",
            "[18/20][2100/3750]\tLoss_D: 0.5215\tLoss_G: 2.6882\n",
            "[18/20][2200/3750]\tLoss_D: 0.1351\tLoss_G: 3.6057\n",
            "[18/20][2300/3750]\tLoss_D: 0.3030\tLoss_G: 3.4167\n",
            "[18/20][2400/3750]\tLoss_D: 0.1323\tLoss_G: 3.9516\n",
            "[18/20][2500/3750]\tLoss_D: 0.2706\tLoss_G: 3.3144\n",
            "[18/20][2600/3750]\tLoss_D: 0.2964\tLoss_G: 2.7524\n",
            "[18/20][2700/3750]\tLoss_D: 0.6411\tLoss_G: 3.8116\n",
            "[18/20][2800/3750]\tLoss_D: 0.0859\tLoss_G: 4.2307\n",
            "[18/20][2900/3750]\tLoss_D: 0.3985\tLoss_G: 4.5677\n",
            "[18/20][3000/3750]\tLoss_D: 0.4209\tLoss_G: 3.5941\n",
            "[18/20][3100/3750]\tLoss_D: 0.6285\tLoss_G: 3.1133\n",
            "[18/20][3200/3750]\tLoss_D: 0.8865\tLoss_G: 3.7030\n",
            "[18/20][3300/3750]\tLoss_D: 0.2296\tLoss_G: 3.8690\n",
            "[18/20][3400/3750]\tLoss_D: 0.7138\tLoss_G: 3.9582\n",
            "[18/20][3500/3750]\tLoss_D: 0.3515\tLoss_G: 4.1247\n",
            "[18/20][3600/3750]\tLoss_D: 0.2198\tLoss_G: 4.2690\n",
            "[18/20][3700/3750]\tLoss_D: 0.3383\tLoss_G: 4.0536\n",
            "Time taken for Epoch 18: 313.72s\n",
            "[19/20][100/3750]\tLoss_D: 0.2408\tLoss_G: 3.5263\n",
            "[19/20][200/3750]\tLoss_D: 0.6786\tLoss_G: 3.4529\n",
            "[19/20][300/3750]\tLoss_D: 0.1718\tLoss_G: 4.4113\n",
            "[19/20][400/3750]\tLoss_D: 0.5330\tLoss_G: 4.0931\n",
            "[19/20][500/3750]\tLoss_D: 0.3269\tLoss_G: 3.5523\n",
            "[19/20][600/3750]\tLoss_D: 0.2050\tLoss_G: 3.8001\n",
            "[19/20][700/3750]\tLoss_D: 0.8018\tLoss_G: 4.0773\n",
            "[19/20][800/3750]\tLoss_D: 0.2062\tLoss_G: 3.2200\n",
            "[19/20][900/3750]\tLoss_D: 0.3608\tLoss_G: 3.2511\n",
            "[19/20][1000/3750]\tLoss_D: 0.3720\tLoss_G: 2.4534\n",
            "[19/20][1100/3750]\tLoss_D: 0.0976\tLoss_G: 4.1863\n",
            "[19/20][1200/3750]\tLoss_D: 0.7413\tLoss_G: 3.0679\n",
            "[19/20][1300/3750]\tLoss_D: 0.4756\tLoss_G: 2.7336\n",
            "[19/20][1400/3750]\tLoss_D: 0.7005\tLoss_G: 3.4790\n",
            "[19/20][1500/3750]\tLoss_D: 0.7689\tLoss_G: 3.1209\n",
            "[19/20][1600/3750]\tLoss_D: 0.4831\tLoss_G: 2.5629\n",
            "[19/20][1700/3750]\tLoss_D: 0.4147\tLoss_G: 4.2218\n",
            "[19/20][1800/3750]\tLoss_D: 0.2578\tLoss_G: 4.6130\n",
            "[19/20][1900/3750]\tLoss_D: 0.2481\tLoss_G: 4.2085\n",
            "[19/20][2000/3750]\tLoss_D: 0.4235\tLoss_G: 2.5361\n",
            "[19/20][2100/3750]\tLoss_D: 0.2516\tLoss_G: 2.8679\n",
            "[19/20][2200/3750]\tLoss_D: 0.0839\tLoss_G: 4.7380\n",
            "[19/20][2300/3750]\tLoss_D: 0.4938\tLoss_G: 3.6457\n",
            "[19/20][2400/3750]\tLoss_D: 0.2826\tLoss_G: 3.6287\n",
            "[19/20][2500/3750]\tLoss_D: 1.5112\tLoss_G: 5.2552\n",
            "[19/20][2600/3750]\tLoss_D: 0.8505\tLoss_G: 3.0379\n",
            "[19/20][2700/3750]\tLoss_D: 0.2955\tLoss_G: 3.5073\n",
            "[19/20][2800/3750]\tLoss_D: 0.4184\tLoss_G: 3.2395\n",
            "[19/20][2900/3750]\tLoss_D: 0.2062\tLoss_G: 4.0461\n",
            "[19/20][3000/3750]\tLoss_D: 0.5314\tLoss_G: 3.6065\n",
            "[19/20][3100/3750]\tLoss_D: 0.6195\tLoss_G: 3.3318\n",
            "[19/20][3200/3750]\tLoss_D: 0.2166\tLoss_G: 3.5834\n",
            "[19/20][3300/3750]\tLoss_D: 0.1650\tLoss_G: 3.3068\n",
            "[19/20][3400/3750]\tLoss_D: 0.1371\tLoss_G: 3.2405\n",
            "[19/20][3500/3750]\tLoss_D: 0.3929\tLoss_G: 3.6983\n",
            "[19/20][3600/3750]\tLoss_D: 0.2835\tLoss_G: 3.2725\n",
            "[19/20][3700/3750]\tLoss_D: 0.1203\tLoss_G: 4.7077\n",
            "Time taken for Epoch 19: 313.99s\n",
            "[20/20][100/3750]\tLoss_D: 0.3437\tLoss_G: 3.0011\n",
            "[20/20][200/3750]\tLoss_D: 0.1848\tLoss_G: 3.4011\n",
            "[20/20][300/3750]\tLoss_D: 0.1079\tLoss_G: 4.2310\n",
            "[20/20][400/3750]\tLoss_D: 0.3375\tLoss_G: 2.2769\n",
            "[20/20][500/3750]\tLoss_D: 0.3180\tLoss_G: 3.1316\n",
            "[20/20][600/3750]\tLoss_D: 0.3078\tLoss_G: 4.5980\n",
            "[20/20][700/3750]\tLoss_D: 0.9942\tLoss_G: 3.4474\n",
            "[20/20][800/3750]\tLoss_D: 0.4620\tLoss_G: 3.0488\n",
            "[20/20][900/3750]\tLoss_D: 0.6239\tLoss_G: 2.6050\n",
            "[20/20][1000/3750]\tLoss_D: 0.3571\tLoss_G: 3.4634\n",
            "[20/20][1100/3750]\tLoss_D: 0.1108\tLoss_G: 4.8596\n",
            "[20/20][1200/3750]\tLoss_D: 0.5956\tLoss_G: 3.7293\n",
            "[20/20][1300/3750]\tLoss_D: 0.5145\tLoss_G: 3.7659\n",
            "[20/20][1400/3750]\tLoss_D: 0.3286\tLoss_G: 3.2676\n",
            "[20/20][1500/3750]\tLoss_D: 0.7665\tLoss_G: 2.8816\n",
            "[20/20][1600/3750]\tLoss_D: 0.3128\tLoss_G: 3.7372\n",
            "[20/20][1700/3750]\tLoss_D: 0.6458\tLoss_G: 4.4665\n",
            "[20/20][1800/3750]\tLoss_D: 0.2153\tLoss_G: 4.7485\n",
            "[20/20][1900/3750]\tLoss_D: 0.1674\tLoss_G: 3.3376\n",
            "[20/20][2000/3750]\tLoss_D: 0.4357\tLoss_G: 2.9256\n",
            "[20/20][2100/3750]\tLoss_D: 0.1649\tLoss_G: 3.9243\n",
            "[20/20][2200/3750]\tLoss_D: 0.1870\tLoss_G: 3.8188\n",
            "[20/20][2300/3750]\tLoss_D: 0.5405\tLoss_G: 3.9013\n",
            "[20/20][2400/3750]\tLoss_D: 0.2449\tLoss_G: 3.8706\n",
            "[20/20][2500/3750]\tLoss_D: 0.6080\tLoss_G: 2.2100\n",
            "[20/20][2600/3750]\tLoss_D: 0.4450\tLoss_G: 3.3951\n",
            "[20/20][2700/3750]\tLoss_D: 0.5455\tLoss_G: 3.4535\n",
            "[20/20][2800/3750]\tLoss_D: 0.2227\tLoss_G: 4.5579\n",
            "[20/20][2900/3750]\tLoss_D: 0.1736\tLoss_G: 5.3513\n",
            "[20/20][3000/3750]\tLoss_D: 0.6593\tLoss_G: 2.5078\n",
            "[20/20][3100/3750]\tLoss_D: 0.4451\tLoss_G: 3.4180\n",
            "[20/20][3200/3750]\tLoss_D: 0.9199\tLoss_G: 3.3922\n",
            "[20/20][3300/3750]\tLoss_D: 0.1646\tLoss_G: 3.5725\n",
            "[20/20][3400/3750]\tLoss_D: 0.4473\tLoss_G: 3.0794\n",
            "[20/20][3500/3750]\tLoss_D: 0.2595\tLoss_G: 2.8905\n",
            "[20/20][3600/3750]\tLoss_D: 0.4030\tLoss_G: 3.9824\n",
            "[20/20][3700/3750]\tLoss_D: 0.3940\tLoss_G: 3.2699\n",
            "Time taken for Epoch 20: 314.00s\n",
            "--------------------------------------------------\n",
            "Training finished!\n",
            "Total Time for Training: 104.73m\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training losses.\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Animation showing the improvements of the generator.\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FPIN1iYJW5dA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "d9845de0-431e-4ee2-b22c-c0c804d78c96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "Starting Training Loop...\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3617b491a47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Training Loop...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs: %d\\nDataset: {}\\nBatch Size: %d\\nLength of Data Loader: %d'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9bTo_FiUzBcu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}