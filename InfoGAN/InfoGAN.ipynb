{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkFBdfGf9ZoF",
        "outputId": "69685948-a549-46f2-c16e-7104719a5dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "!pip install utils\n",
        "from utils import *\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import numpy as np\n",
        "import time\n",
        "% matplotlib inline\n",
        "\n",
        "batch_size=16\n",
        "dataset = dset.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "z8vWKcS0Ip1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = dataset[0]\n",
        "plt.imshow(to_pil_image(img))\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "mjD1bImf_Gey",
        "outputId": "5144a246-f019-40a8-f66f-1bf1a08ec9b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "L3ibrI-qTE6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tconv1 = nn.ConvTranspose2d(74, 1024, 1, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(1024)\n",
        "\n",
        "        self.tconv2 = nn.ConvTranspose2d(1024, 128, 7, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.tconv3 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.tconv4 = nn.ConvTranspose2d(64, 1, 4, 2, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.tconv1(x)))\n",
        "        x = F.relu(self.bn2(self.tconv2(x)))\n",
        "        x = F.relu(self.bn3(self.tconv3(x)))\n",
        "\n",
        "        img = torch.sigmoid(self.tconv4(x))\n",
        "\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(1024)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n",
        "        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n",
        "\n",
        "        return x\n",
        "\n",
        "class DHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(1024, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.sigmoid(self.conv(x))\n",
        "\n",
        "        return output\n",
        "\n",
        "class QHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1024, 128, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv_disc = nn.Conv2d(128, 10, 1)\n",
        "        self.conv_mu = nn.Conv2d(128, 2, 1)\n",
        "        self.conv_var = nn.Conv2d(128, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n",
        "\n",
        "        disc_logits = self.conv_disc(x).squeeze()\n",
        "\n",
        "        mu = self.conv_mu(x).squeeze()\n",
        "        var = torch.exp(self.conv_var(x).squeeze())\n",
        "\n",
        "        return disc_logits, mu, var"
      ],
      "metadata": {
        "id": "dSv9uEb9ajKc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight init & Parameter"
      ],
      "metadata": {
        "id": "XpYS-2NdIibg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_init(model):\n",
        "  classname = model.__class__.__name__\n",
        "  if classname.find(\"conv\") != -1:\n",
        "    torch.nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "  elif classname.find(\"BatchNorm\") != -1:\n",
        "    torch.nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "    torch.nn.init.constant_(model.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "7BHwd0liEmk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8a026d-1d3b-44c7-b202-0ce8900e3688"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (dis): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2)\n",
              "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.2)\n",
              "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): LeakyReLU(negative_slope=0.2)\n",
              "    (9): Conv2d(256, 1024, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (10): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (adv_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  (aux_layer): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (latent_layer): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "MwbSroCja861"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalNLLLoss:\n",
        "    \"\"\"\n",
        "    Calculate the negative log likelihood\n",
        "    of normal distribution.\n",
        "    This needs to be minimised.\n",
        "    Treating Q(cj | x) as a factored Gaussian.\n",
        "    \"\"\"\n",
        "    def __call__(self, x, mu, var):\n",
        "        \n",
        "        logli = -0.5 * (var.mul(2 * np.pi) + 1e-6).log() - (x - mu).pow(2).div(var.mul(2.0) + 1e-6)\n",
        "        nll = -(logli.sum(1).mean())\n",
        "\n",
        "        return nll\n",
        "def noise_sample(n_dis_c, dis_c_dim, n_con_c, n_z, batch_size, device):\n",
        "    \"\"\"\n",
        "    Sample random noise vector for training.\n",
        "    INPUT\n",
        "    --------\n",
        "    n_dis_c : Number of discrete latent code.\n",
        "    dis_c_dim : Dimension of discrete latent code.\n",
        "    n_con_c : Number of continuous latent code.\n",
        "    n_z : Dimension of iicompressible noise.\n",
        "    batch_size : Batch Size\n",
        "    device : GPU/CPU\n",
        "    \"\"\"\n",
        "\n",
        "    z = torch.randn(batch_size, n_z, 1, 1, device=device)\n",
        "\n",
        "    idx = np.zeros((n_dis_c, batch_size))\n",
        "    if(n_dis_c != 0):\n",
        "        dis_c = torch.zeros(batch_size, n_dis_c, dis_c_dim, device=device)\n",
        "        \n",
        "        for i in range(n_dis_c):\n",
        "            idx[i] = np.random.randint(dis_c_dim, size=batch_size)\n",
        "            dis_c[torch.arange(0, batch_size), i, idx[i]] = 1.0\n",
        "\n",
        "        dis_c = dis_c.view(batch_size, -1, 1, 1)\n",
        "\n",
        "    if(n_con_c != 0):\n",
        "        # Random uniform between -1 and 1.\n",
        "        con_c = torch.rand(batch_size, n_con_c, 1, 1, device=device) * 2 - 1\n",
        "\n",
        "    noise = z\n",
        "    if(n_dis_c != 0):\n",
        "        noise = torch.cat((z, dis_c), dim=1)\n",
        "    if(n_con_c != 0):\n",
        "        noise = torch.cat((noise, con_c), dim=1)\n",
        "\n",
        "    return noise, idx"
      ],
      "metadata": {
        "id": "CiAiR84sbM0U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the network.\n",
        "netG = Generator().to(device)\n",
        "netG.apply(weight_init)\n",
        "print(netG)\n",
        "\n",
        "discriminator = Discriminator().to(device)\n",
        "discriminator.apply(weight_init)\n",
        "print(discriminator)\n",
        "\n",
        "netD = DHead().to(device)\n",
        "netD.apply(weight_init)\n",
        "print(netD)\n",
        "\n",
        "netQ = QHead().to(device)\n",
        "netQ.apply(weight_init)\n",
        "print(netQ)\n",
        "\n",
        "# Loss for discrimination between real and fake images.\n",
        "criterionD = nn.BCELoss()\n",
        "# Loss for discrete latent code.\n",
        "criterionQ_dis = nn.CrossEntropyLoss()\n",
        "# Loss for continuous latent code.\n",
        "criterionQ_con = NormalNLLLoss()\n",
        "\n",
        "# Adam optimiser is used.\n",
        "optimD = optim.Adam([{'params': discriminator.parameters()}, {'params': netD.parameters()}], lr=0.001, betas=(0.5, 0.99))\n",
        "optimG = optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=0.001, betas=(0.5,0,99))\n",
        "\n",
        "# Fixed Noise\n",
        "z = torch.randn(100, 62, 1, 1, device=device)\n",
        "fixed_noise = z\n",
        "idx = np.arange(10).repeat(10)\n",
        "dis_c = torch.zeros(100, 1, 10, device=device)\n",
        "dis_c[torch.arange(0, 100), i, idx] = 1.0\n",
        "\n",
        "dis_c = dis_c.view(100, -1, 1, 1)\n",
        "\n",
        "fixed_noise = torch.cat((fixed_noise, dis_c), dim=1)\n",
        "\n",
        "con_c = torch.rand(100, 2, 1, 1, device=device) * 2 - 1\n",
        "fixed_noise = torch.cat((fixed_noise, con_c), dim=1)\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# List variables to store results pf training.\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "print(\"-\"*25)\n",
        "print(\"Starting Training Loop...\\n\")\n",
        "print('Epochs: %d\\nDataset: {}\\nBatch Size: %d\\nLength of Data Loader: %d'.format(\"MNIST\") % (30, 16, len(data_loader)))\n",
        "print(\"-\"*25)\n",
        "\n",
        "start_time = time.time()\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for i, (data, _) in enumerate(data_loader, 0):\n",
        "        # Get batch size\n",
        "        b_size = data.size(0)\n",
        "        # Transfer data tensor to GPU/CPU (device)\n",
        "        real_data = data.to(device)\n",
        "\n",
        "        # Updating discriminator and DHead\n",
        "        optimD.zero_grad()\n",
        "        # Real data\n",
        "        label = torch.full((b_size, ), real_label, device=device)\n",
        "        output1 = discriminator(real_data)\n",
        "        probs_real = netD(output1).view(-1)\n",
        "        loss_real = criterionD(probs_real, label)\n",
        "        # Calculate gradients.\n",
        "        loss_real.backward()\n",
        "\n",
        "        # Fake data\n",
        "        label.fill_(fake_label)\n",
        "        noise, idx = noise_sample(1, 10, 2, 62, b_size, device)\n",
        "        fake_data = netG(noise)\n",
        "        output2 = discriminator(fake_data.detach())\n",
        "        probs_fake = netD(output2).view(-1)\n",
        "        loss_fake = criterionD(probs_fake, label)\n",
        "        # Calculate gradients.\n",
        "        loss_fake.backward()\n",
        "\n",
        "        # Net Loss for the discriminator\n",
        "        D_loss = loss_real + loss_fake\n",
        "        # Update parameters\n",
        "        optimD.step()\n",
        "\n",
        "        # Updating Generator and QHead\n",
        "        optimG.zero_grad()\n",
        "\n",
        "        # Fake data treated as real.\n",
        "        output = discriminator(fake_data)\n",
        "        label.fill_(real_label)\n",
        "        probs_fake = netD(output).view(-1)\n",
        "        gen_loss = criterionD(probs_fake, label)\n",
        "\n",
        "        q_logits, q_mu, q_var = netQ(output)\n",
        "        target = torch.LongTensor(idx).to(device)\n",
        "        # Calculating loss for discrete latent code.\n",
        "        dis_loss = 0\n",
        "        dis_loss += criterionQ_dis(q_logits[:, 2*10 : 2*10 + 10], target[2])\n",
        "\n",
        "        # Calculating loss for continuous latent code.\n",
        "        con_loss = 0\n",
        "        con_loss = criterionQ_con(noise[:, 62+ 1*10 : ].view(-1, 2), q_mu, q_var)*0.1\n",
        "\n",
        "        # Net loss for generator.\n",
        "        G_loss = gen_loss + dis_loss + con_loss\n",
        "        # Calculate gradients.\n",
        "        G_loss.backward()\n",
        "        # Update parameters.\n",
        "        optimG.step()\n",
        "\n",
        "        # Check progress of training.\n",
        "        if i != 0 and i%100 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
        "                  % (epoch+1, 30, i, len(data_loader), \n",
        "                    D_loss.item(), G_loss.item()))\n",
        "\n",
        "        # Save the losses for plotting.\n",
        "        G_losses.append(G_loss.item())\n",
        "        D_losses.append(D_loss.item())\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "    # epoch_time = time.time() - epoch_start_time\n",
        "    # print(\"Time taken for Epoch %d: %.2fs\" %(epoch + 1, epoch_time))\n",
        "    # # Generate image after each epoch to check performance of the generator. Used for creating animated gif later.\n",
        "    # with torch.no_grad():\n",
        "    #     gen_data = netG(fixed_noise).detach().cpu()\n",
        "    # img_list.append(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True))\n",
        "\n",
        "    # # Generate image to check performance of generator.\n",
        "    # if((epoch+1) == 1 or (epoch+1) == params['num_epochs']/2):\n",
        "    #     with torch.no_grad():\n",
        "    #         gen_data = netG(fixed_noise).detach().cpu()\n",
        "    #     plt.figure(figsize=(10, 10))\n",
        "    #     plt.axis(\"off\")\n",
        "    #     plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
        "    #     plt.savefig(\"Epoch_%d {}\".format(params['dataset']) %(epoch+1))\n",
        "    #     plt.close('all')\n",
        "\n",
        "    # # Save network weights.\n",
        "    # if (epoch+1) % params['save_epoch'] == 0:\n",
        "    #     torch.save({\n",
        "    #         'netG' : netG.state_dict(),\n",
        "    #         'discriminator' : discriminator.state_dict(),\n",
        "    #         'netD' : netD.state_dict(),\n",
        "    #         'netQ' : netQ.state_dict(),\n",
        "    #         'optimD' : optimD.state_dict(),\n",
        "    #         'optimG' : optimG.state_dict(),\n",
        "    #         'params' : params\n",
        "    #         }, 'checkpoint/model_epoch_%d_{}'.format(params['dataset']) %(epoch+1))\n",
        "\n",
        "# training_time = time.time() - start_time\n",
        "# print(\"-\"*50)\n",
        "# print('Training finished!\\nTotal Time for Training: %.2fm' %(training_time / 60))\n",
        "# print(\"-\"*50)\n",
        "\n",
        "# # Generate image to check performance of trained generator.\n",
        "# with torch.no_grad():\n",
        "#     gen_data = netG(fixed_noise).detach().cpu()\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# plt.axis(\"off\")\n",
        "# plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
        "# plt.savefig(\"Epoch_%d_{}\".format(params['dataset']) %(params['num_epochs']))\n",
        "\n",
        "# # Save network weights.\n",
        "# torch.save({\n",
        "#     'netG' : netG.state_dict(),\n",
        "#     'discriminator' : discriminator.state_dict(),\n",
        "#     'netD' : netD.state_dict(),\n",
        "#     'netQ' : netQ.state_dict(),\n",
        "#     'optimD' : optimD.state_dict(),\n",
        "#     'optimG' : optimG.state_dict(),\n",
        "#     'params' : params\n",
        "#     }, 'checkpoint/model_final_{}'.format(params['dataset']))\n",
        "\n",
        "\n",
        "# # Plot the training losses.\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "# plt.plot(G_losses,label=\"G\")\n",
        "# plt.plot(D_losses,label=\"D\")\n",
        "# plt.xlabel(\"iterations\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend()\n",
        "# plt.savefig(\"Loss Curve {}\".format(params['dataset']))\n",
        "\n",
        "# # Animation showing the improvements of the generator.\n",
        "# fig = plt.figure(figsize=(10,10))\n",
        "# plt.axis(\"off\")\n",
        "# ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "# anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "# anim.save('infoGAN_{}.gif'.format(params['dataset']), dpi=80, writer='imagemagick')\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wnnyRIiOa-NM",
        "outputId": "6de3255e-987f-4b07-b5af-d38d34815a37"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (tconv1): ConvTranspose2d(74, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (tconv2): ConvTranspose2d(1024, 128, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (tconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (tconv4): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "Discriminator(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 1024, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "DHead(\n",
            "  (conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "QHead(\n",
            "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_disc): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_mu): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_var): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "-------------------------\n",
            "Starting Training Loop...\n",
            "\n",
            "Epochs: 30\n",
            "Dataset: MNIST\n",
            "Batch Size: 16\n",
            "Length of Data Loader: 3750\n",
            "-------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a4b8ebf956cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mprobs_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterionD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Calculate gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mloss_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3081\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
          ]
        }
      ]
    }
  ]
}